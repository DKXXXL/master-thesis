

We formalize our language as a deep embedding in a type theory with QIIT types. Every judgement is a (dependent) QIIT \textit{type} and all judgement derivations are well-typed QIIT terms. (Otherwise how can they be encoded in Agda?) There are four standard judgement forms in MLTT,
well-typed contexts $\goodCtx{\Gamma}{l}$, well-typed types
$\goodType{\Gamma}{T}{l}$, well-typed terms $\goodTerm{\Gamma}{t}{T}$, and
well-typed substitutions $\goodSub{\Gamma}{\gamma}{\Delta}$. These four judgements (QIIT types) are
mutually recursively defined together. Our presentation
follows the style of~\citet{kaposi2019gluing}, but for readability we
omit the universe levels. We still working on predicative MLTT.
%\YZ{What's the distinction of judgments vs. sequents?}.\EDJreply{I am not sure about the correct terminology here. Here I want to say "even underivable judgement has to be well-typed". That's the main reason I spell out the fake Agda code there. I actually want the reader to have intrinsic-typed syntax in mind all the time (like read conventional math but acknowledge we are manipulating Agda)}\EDJreply{I rephrase that so there won't be confusion for the future readers. Please check}
Latex-wise, we spell out these \textit{well-formedness rules} of type
judgements and their Agda counterparts to make things more accessible. Of
course, a well-formed judgement is not necessarily derivable, just as
a well-formed QIIT type is not necessarily inhabited. 


Due to our intrinsic setting, \textbf{we can and will omit a lot of
presumptions of the typing rules}. This can work because we are using
QIIT and everything is intrinsically well-formed. For example, we don't
spell out that the rule \ruleref{Type Universe} requires a well-formed
context, even though it does implicitly, \textbf{because it is not
possible to have ill-formed contexts in our intrinsic setting}. This is
a bit unusual for conventional extrinsic setting where they will put
well-formedness of context everywhere in a lot of term judgements. We
consider this as one advantage of using intrinsic setting---this
well-formed context is usually attached to some other presumptions thus
inferrable and can be considered as ``boilerplate code''. Free of
such boilerplate code, our intrinsic setting provides a more concise
representation.

Quotient is used to represent definitional equality (aka judgemental
equality) between QIIT types concisely.
This way, for all four kinds of judgements we are
using, there is always equality among these data. Doing so, we can omit
some obvious equality judgements. Most of the reasoning can be formulated
using the \textit{algebra} of QIIT (mapping out function from this
quotient data-type). 

Now we highlight some other special features that differ from a more
conventional setting: (1) This modern formulation of type theory does not
have an operational semantics but only equality.\footnote{Later we will prove
canonicity which can imply a certain level of computational ability of
our theory}
%We will recover canonicity afterwards, which implies the computational ability of our theory. 
(2) Instead of using meta-level substitution, we use explicit
substitution and de Bruijn indices in our intrinsic formulation. This is
also called substitution calculus in the literature and is favoured due
to its closedness categorical semantic.
(3) We are dealing with quotient data, so we are actually manipulating
equivalence classes of terms.

We quickly review the substitution calculus.
Substitution is very (if not the most) important because function is
first-class citizens, and can be applied (almost) everywhere and can return
(almost) everything, thus we require the resulting substitution to
commute with most (if not all) type/term constructs. 

A term $\goodTerm{\Gamma}{t}{A}$ can be understood as one term $t$ of
type $A$, with a bunch of holes (of type $\Gamma$) inside the term $t$.
A substitution $\goodSub{\Gamma}{\gamma}{\Delta}$ can be similarly
understood in the way that $\gamma$ will output a \textbf{series} of
(dependently-typed related) terms of types $\Delta$, parametrized by
$\Gamma$ (i.e., we can consider there are holes of type $\Gamma$ in $\gamma$).
Thus (1) \ruleref{Sub Extend} looks like concatenating one
series of terms with a new term (the weird looking type of
$\goodTerm{\Gamma}{t}{A[\sigma]}$ is because we need $A$ to be typed in
the context $\Delta$ so that we can use \ruleref{Context Extension} to
create new context); (2) we have \ruleref{Proj Subst-1} to extract a
subpart of a given substitution; (3) \ruleref{Proj-Ext} explains why
substitution really looks like a (deeply-nested) pair. 

Since the $\Gamma$ before the $\vdash$ is always indicating the types of
``holes'', this explains the \ruleref{Term Subst} and \ruleref{Type
Subst}: given a term $\goodTerm{\Delta}{t}{A}$ and a substitution
$\goodSub{\Gamma}{\gamma}{\Delta}$, we will have a new term
$\goodTerm{\Gamma}{t[\gamma]}{A[\gamma]}$ after the substitution---this
substitution can be understood as ``filling all the holes''. Once all
the holes are filled with a given substitution, the new holes all come
from the substitution itself.
Consecutive substitutions can be composed using \ruleref{Sub Comp}, because
all the holes are always from the last substitutions.

Note that, for simplicity, we will often write $\pi_1$ as a
shorthand for ${\pi_1~"id"}$, typed as
$\goodSub{\Gamma,A}{\pi_1~"id"}{\Gamma}$, and $\pi_2$ as a shorthand
for $\pi_2~"id"$, typed as $\goodTerm{\Gamma, A}{\pi_2~"id"}{A[\pi_1]}$.



The core language builds on MLTT and adds four new judgement forms.
Among them, sealing judgement $\goodSeal{\Gamma}{\_}{\sigma}{A}$ is just a
shorthand for term judgement
$\goodTerm{\Gamma , \cC \sigma}{\_}{A[\pi_1]}$ where $A$ is a type.



\newcommand\mathboxtext[1]{
  \fcolorbox{black}{faint-gray}{\ensuremath{#1}}
}

\begin{figure}[!htb]
  \begin{align*}
    &\Gamma~:~"Con"&&\mathboxtext{\goodCtx{\Gamma}{}} &&T~:~"Ty"~\Gamma&&\mathboxtext{\goodType{\Gamma}{T}{}}  &&\gamma~:~"Tms"~\Gamma~\Delta&&\mathboxtext{\goodSub{\Gamma}{\gamma}{\Delta}}  \\ & t~:~"Tm"~\Gamma~T&&\mathboxtext{\goodTerm{\Gamma}{t}{T}} 
    &&\sigma~:~"Sig"~\Gamma~n&&\mathboxtext{\goodSig{\Gamma}{\sigma}{n}}  &&\tau~:~"WSig"~\Gamma~n&&\mathboxtext{\goodWSig{\Gamma}{\tau}{n}} \\ &h~:~"Inh"~\Gamma~\sigma_1~\sigma_2&&\mathboxtext{\goodInh{\Gamma}{h}{\sigma}{\tau}} && f~:~"Seal"~\Gamma~\sigma~T&&\mathboxtext{\goodSeal{\Gamma}{f}{\sigma}{A}}\YZ{A little unfriendly to the reader that there are three different things that sigma can range over. Besides, later you also use gamma to range over substitutions and s to range over W-types, which add to the confusion.}\EDJreply{Fair point. I have fixed fix sigma and tau to be about signatures and W signature, and use gamma as substitutions}
  \end{align*}
\caption{Judgement forms, as Agda types and as presented in this section.}
\end{figure}

\begin{figure}[!htb]
  \begin{minipage}[b]{0.3\linewidth}
      $$
      \Rule[name=Tm]
      {\goodCtx{\Gamma}{i} \quad \goodType{\Gamma}{T}{j}}
      {\goodTerm{\Gamma}{\_}{T}}
      $$
      $$
      \Rule[name=Tms]
      {\goodCtx{\Gamma}{i} \quad \goodCtx{\Delta}{i}}
      {\goodSub{\Gamma}{\_}{\Delta} \text{ is well-formed}}
      $$
      $$
      \Rule[name=Sig]
      {\goodCtx{\Gamma}{i} \quad n \in \nat}
      {\goodSig{\Gamma}{\_}{n} \text{ is well-formed}}
      $$
      $$
      \Rule[name=Seal]
      {\goodCtx{\Gamma}{i} \quad \goodSig{\Gamma}{\sigma}{n} 
      \quad \goodType{\Gamma}{A}{} }
      {\goodSeal{\Gamma}{\_}{\sigma}{A} \text{ is well-formed}}
      $$\YZ{Doesn't the left column show well-formedness rules for ONLY TWO of the four new judgments? Besides, are these rules used anywhere in the following? Seems a bit unusual to have well-formedness rules for judgments per se.}\EDJreply{Yes. Right column show all the well-formedness rule for all the judgement. That is unusual because it is a direct translation from QIIT. }
  \end{minipage}
  \begin{minipage}[b]{0.6\linewidth}
    \begin{minted}[]{agda}
      data Con   : Set 
      data Ty    : Con → Set   
      data Tms   : Con → Con → Set 
      data Tm    : (Γ : Con) → Ty Γ  → Set 
      data Sig  : Con → ℕ → Set
      data WSig : Con → ℕ → Set 
      data Inh  : (Γ : Con) → Sig Γ n → Sig Γ m → Set
      Seal : (Γ : Con) → Sig Γ n → Sig Γ n → Set
    \end{minted}
  \end{minipage}

\caption{Well-formedness rules of the judgements}
\end{figure}





% \begin{minted}[texcomments]{Coq}
%   Γ : Con  (* $\goodCtx{\Gamma}{}$ *) 
% \end{minted}
% T : Ty Γ (* $\goodType{\Gamma}{T}{}$ *)       σ : Tms Γ Δ {- $\goodSub{\Gamma}{\sigma}{\Delta}$ -}        t : Tm Γ T {- $\goodTerm{\Gamma}{t}{T}$ -}





We will have dependent function types
and dependent pair types. Dependent pair type is used to model Coq
module, which is useful when we need to model the ``compilation'' from
linkages to modules. We also have $\beta,\eta$-rule for both dependent
function type and dependent pair type.
The substitution law for these two
require \textit{de Bruijn lifting}: for a given substitution
$\goodTerm{\Gamma}{\sigma}{\Delta}$ and a type
$\goodType{\Delta}{A}{}$, we define its de Bruijn lifting
$\goodTerm{\Gamma,A[\sigma]}{\sigma^\uparrow := (\sigma \circ \pi_1, \pi_2)}{\Delta, A}$ . Intuitively speaking, de Bruijn lifting is to ``fill all the holes except the last one''.

Because in dependent type, function now can return type, of which the type is ``type of type'', \textit{the universe} $\cU$. We follow the style of \textit{type universe à la Tarski}~\cite{hofmann1997syntax} and
distinguish types from their \textit{codes or names}, and thus we use
$El\ T$ as the type given \textit{type name} $T : \cU$.
In this case, (1) $\cU$ is the type including the \textit{codes or
names} of types, and (2) $T$ is not allowed to locate at type position
(i.e., at the rightmost position of a term judgement) but $El \ T$ is.
"c" is the ``inverse'' of $El$, obtaining  the \underline{"c"}ode of a
type, with the following two equations $"c" (El~T) \equiv T$ and $El
("c"~T) \equiv T$.
Recall that we are actually using predicative universe, so we actually
have different levels of universes $\cU_j$.
We omit universe levels for conciseness.


  \label{fig:rules:well-typed-ctx}
\judgebox{\goodCtx{\Gamma}{i}}
$$ 
\Rule[name=Empty Context]{}{\goodCtx{\cdot}{0}} 
\quad
\Rule[name=Context Extension]
{\goodCtx{\Gamma}{i} \quad \goodType{\Gamma}{A}{j}}
{\goodCtx{\Gamma, A}{i \cup j}}  
$$


\judgebox{ \goodType{\Gamma}{T}{i} }
$$
\Rule[name=Type Universe]
{}
{\goodType{\Gamma}{\cU}{j + 1}}
\quad 
\Rule[name=Boolean]
{}
{\goodType{\Gamma}{\cB}{0}}
\quad 
\Rule[name=Bottom]
{}
{\goodType{\Gamma}{\bot}{0}}
\quad 
\Rule[name=Function]
{\goodType{\Gamma}{A}{j} 
  \quad \goodType{\Gamma, A}{B}{k}}
{\goodType{\Gamma}{\Pi A B}{j \cup k}}
$$

$$
\quad 
\Rule[name=Func/DPair Subst]
{\goodSub{\Gamma}{\gamma}{\Delta}
\quad \goodType{\Delta}{A}{} 
\quad \goodType{\Delta, A}{B}{}
}
{
  \goodType{\Gamma}{(\Pi A B)[\gamma] \equiv \Pi A[\gamma] B[\gamma^\uparrow] }{j \cup k}
  \quad 
  \goodType{\Gamma}{(\Sigma A B)[\gamma] \equiv \Sigma A[\gamma] B[\gamma^\uparrow] }{j \cup k}
}
$$
%\YZ{What is the requirement on Delta?}
%\EDJreply{ Delta here is of type Con and thus Delta here should be a well-typed Context. This is another issue I want to talk about, in Agda these kinds of stuff is inferred (so the reader can infer them as well). For example, we know delta is at the place of context, so it is a context, but we don't need to specify that it is a ``well-typed context'' because every context is well-typed in this intrinsic-typing. What's more, I think adding this extra judgement here just cause significant code bloat (like what I complained to you before I know how to use implcit variable in agda. For example, TYPE SUBST, there will be two more judgements (with no more information there) ) (Another reason I prefer fake agda formulation) }\YZreply{I was thinking about 'Delta |- A'. I suppose it is also implicitly enforced via intrinsically typed syntax. Seems to me it is worth stating, however, or otherwise the rule appears to say that Delta can be any context as long as Gamma |- gamma : Delta.}\EDJreply{You are absolutely right! I think Delta |- A, even though inferrable, mentioning it is good, also some information are B is also ok, please check, resolve if ok, thanks!}
$$
\Rule[name=Type Subst]
{\goodType{\Delta}{T}{j} 
  \quad {\goodSub{\Gamma}{\gamma}{\Delta}}}
{\goodType{\Gamma}{T[\gamma]}{j}}
\quad
\Rule[name=Base Type Subst]
{\goodSub{\Gamma}{\gamma}{\Delta}}
{\goodType{\Gamma}{\cU[\gamma] \equiv \cU }{j + 1} \quad
  \goodType{\Gamma}{\cB[\gamma] \equiv \cB}{0} \quad 
  \goodType{\Gamma}{\bot[\gamma] \equiv \bot}{0}
}
$$
\judgebox{ \goodTerm{\Gamma}{t}{T} }
$$
\Rule[]
{\goodType{\Gamma}{T}{j}}
{\goodTerm{\Gamma}{"c" \ T}{\cU}
}\quad
\Rule[]
{\goodTerm{\Gamma}{T}{\cU}}
{\goodType{\Gamma}{El \ T}{j}}
\quad
\Rule
{}
{\goodTerm{\Gamma}{"tt", "ff"}{\cB}}
\quad 
\Rule[name=Term Subst]
{\goodTerm{\Delta}{t}{T}
  \quad {\goodSub{\Gamma}{\gamma}{\Delta}}}
{\goodTerm{\Gamma}{t[\gamma]}{T[\gamma]}}
$$
$$
\Rule[]
{\goodTerm{\Gamma, A}{t}{B}}
{\goodTerm{\Gamma}{\lambda t}{\Pi A B}}
\quad 
\Rule[]
{\goodTerm{\Gamma}{u}{A} 
\quad \goodTerm{\Gamma}{v}{B[(id, u)]}}
{\goodTerm{\Gamma}{(u,v)}{\Sigma A B}}
\quad 
\Rule[]
{\goodTerm{\Gamma}{t}{\Sigma A B}}
{\goodTerm{\Gamma}{"pjl" \ t}{A}
\quad \goodTerm{\Gamma}{"pjr" \  t}{B[(id, "pjl" \  t)]}
}
$$
$$
\Rule
{}
{\goodTerm{\Gamma}{(\lambda t)[\gamma] \equiv \lambda (t[\gamma^\uparrow])}{\Pi A B}
\quad \goodTerm{\Gamma}{(u,v)[\gamma] \equiv (u[\gamma],v[\gamma])}{\Sigma A B}
\quad \goodType{\Gamma}{El \ (T[\gamma]) \equiv (El \ T) [\gamma]}{}
}
$$

$$
\Rule[name=Base Type/Term Subst]
{\goodSub{\Gamma}{\gamma}{\Delta}}
{\goodType{\Gamma}{(El \ T)[\gamma] \equiv El \ (T[\gamma]) }{j} \quad
 \goodTerm{\Gamma}{"tt"[\gamma] \equiv "tt"}{\cB} \quad 
 \goodTerm{\Gamma}{"ff"[\gamma] \equiv "ff"}{\cB} 
}
$$
\judgebox{\goodSub{\Gamma}{\sigma}{\Delta}}
$$
\Rule[name=Ept Subst]
{}{\goodSub{\Gamma}{\epsilon}{\cdot}}
\quad
\Rule[]
{}{\goodSub{\Gamma}{"id"}{\Gamma}}
\quad
\Rule[name=Sub Comp]{
  \goodSub{\Delta}{\delta}{\Theta}
  \quad \goodSub{\Gamma}{\gamma}{\Delta} 
}{\goodSub{\Gamma}{\delta \circ \gamma}{\Theta}}
\Rule[name=Sub Extend]
{\goodSub{\Gamma}{\sigma}{\Delta} \quad \goodTerm{\Gamma}{t}{A[\sigma]}}
{\goodSub{\Gamma}{(\sigma, t)}{(\Delta, A)}}
$$

$$
\Rule[name=Proj Subst-1]
{\goodSub{\Gamma}{\sigma}{(\Delta, A)}}
{\goodSub{\Gamma}{\pi_1 \sigma}{\Delta}}
\quad
\Rule[name=Proj Subst-2]
{\goodSub{\Gamma}{\sigma}{(\Delta, A)}}
{\goodSub{\Gamma}{\pi_2 \sigma}{A[\pi_1 \sigma]}}
\quad
\Rule[name=Proj-Ext]
{}
{\goodSub{\Gamma}{(\pi_1 \sigma, \pi_2 \sigma) \equiv \sigma}{\Delta}}
$$

We have shown some exemplar rules for all four standard types of
judgments. Now we focus on the newly introduced facility. 


We have two kinds of signatures, one for inductive types, the other for linkages.



\judgebox{\goodWSig{\Gamma}{\tau}{n}}
$$
\Rule[name=Emp-WSig]
{}
{\goodWSig{\Gamma}{w\cdot}{0}}
\quad
\Rule[name=WSig-Add]
{\goodWSig{\Gamma}{\tau}{n}
  \quad \goodType{\Gamma}{A}{i}
  \quad \goodType{\Gamma, A}{B}{i}}
{\goodWSig{\Gamma}{w^+ \  \tau \  A \  B}{n+1}}
\quad
\Rule[name=Ind-Univ]
{\goodWSig{\Gamma}{\tau}{n}}
{\goodType{\Gamma}{\bW \tau}{i}}
$$
%\YZ{Is there an introduction rule for terms of type 'bW sigma'?}
%\EDJreply{Yes there is. I omit it because it is a singleton type, please see my newly added explanation below.}

$$
\Rule[name=WSig-Proj]
{\goodWSig{\Gamma}{\tau}{n} \quad j < n}
{\goodType{\Gamma}{\pi^j_1 \tau}{i} \quad \goodType{\Gamma, \pi^j_1 \tau}{\pi^j_2  \tau}{i}}
\quad
\Rule[name=Ind-Sig]
{\goodWSig{\Delta}{\tau}{n}
  \quad {\goodSub{\Gamma}{\gamma}{\Delta}}}
{\goodWSig{\Gamma}{\tau[\gamma]}{n}
  \quad \goodType{\Gamma}{W (\tau[\gamma]) \equiv (W \tau)[\gamma]}{i}}
$$

$$
\Rule[name=Ind-Type]
{\goodTerm{\Gamma}{T}{\bW \tau}}
{\goodTerm{\Gamma}{"W" \ T}{\cU}}
\quad
\Rule[name=Ind-Term]
{\goodTerm{\Gamma}{T}{\bW \tau}
  \quad \goodTerm{\Gamma}{a}{\pi^j_1\tau}
  \quad \goodTerm{\Gamma, \pi^j_2\tau[(id, a)]}{b}{El~("W"~T)}}
{\goodTerm{\Gamma}{"Wsup"~T~a~b}{El~("W"~T)} }
$$


Recall in W-type~\cite{martin1982constructive}, a pair of type $x : A
\vdash B(x)$ decides a W-type. To simulate extensible inductive types, we
have to equip our inductive types with multiple constructors, and for
simplicity, each constructor has a fixed form \mintinline{agda}{cstrᵢ :
(x : Aᵢ) → (Bᵢ x → W) → W}.
Thus, we use a list of pairs ($A_i, B_i$) as the signature of one
inductive type, and given an inductive type signature, we use
\ruleref{WSig-Proj} to extract the corresponding $A_i, B_i$.

Of course we need to put an eye on the substitution law for each piece
of the syntax. Here $\bW \sigma$ is a large singleton
type~\cite{stone2000}, and it only has one ``element'', the inductive
type itself, inside. We formulate in this cumbersome way because we want
to have inductive type to be a field element and exposing the
constructors at the type level for later \textit{pattern-matching
exhaustiveness checking} (i.e. if an inductive type as field element has type
$\cU$, then no information about the inductive type is exposed).
 

The formulation of our recursor is closely related to that of linkages,
so we will postpone their description.




\judgebox{\goodSig{\Gamma}{\sigma}{n} }
$$
\Rule[name=Lnkg Type/Compile]
{\goodSig{\Gamma}{\sigma}{n}}
{\goodType{\Gamma}{\cL \sigma}{i}
\quad \goodType{\Gamma}{\cC \sigma}{}}
\quad
\Rule[name=Sig/Lnkg Subst]
{\goodSig{\Delta}{\sigma}{n}
  \quad {\goodSub{\Gamma}{\gamma}{\Delta}}}
{\goodSig{\Gamma}{\sigma[\gamma]}{n}
  \quad \goodType{\Gamma}{\cL (\sigma[\gamma]) \equiv (\cL \sigma)[\gamma]}{i}}
$$

$$
\Rule[name=Ept Sig]
{}
{\goodSig{\Gamma}{\nu\cdot}{0}}
\quad
\Rule[name=Sig Add]
{\goodSig{\Gamma}{\sigma}{n} 
 \quad \goodSeal{\Gamma}{f}{\sigma}{A}
 \quad \goodType{\Gamma, A}{T}{i}}
{\goodSig{\Gamma}{(\nu^+ \ \sigma \ \{f\} \ T)}{n+1}}
$$

$$ 
\Rule[name=Sig Proj]
{\goodSig{\Gamma}{\sigma}{n+1}}
{\goodSig{\Gamma}{p_1\nu \ \sigma}{n}
\\ \goodType{\Gamma}{p_1\nu' \ \sigma}{}
\\ \goodSeal{\Gamma}{p_f\nu \  \sigma}{p_1\nu \  \sigma}{p_1\nu' \sigma}
\\ \goodType{\Gamma, p_1\nu' \ \sigma}{p_2\nu \ \sigma}{}
}
$$

$$
\Rule[name=Ept Lnkg]
{}
{\goodTerm{\Gamma}{\mu\cdot}{\cL \nu\cdot}}
\quad
\Rule[name=Lnkg Add]
{ \goodTerm{\Gamma}{o}{\cL \sigma} 
\quad  \goodSeal{\Gamma}{f}{\sigma}{A} 
 \quad \goodTerm{\Gamma, A}{t}{T}
}
{\goodTerm{\Gamma}{(\mu^+ \ o \ \{f\} \ t)}{\cL(\nu^+ \ \sigma \ \{f\} \ T)}}
$$

$$
\Rule[name=Lnkg Proj]
{\goodTerm{\Gamma}{o}{\cL\sigma}}
{\goodTerm{\Gamma}{p_1\mu \ o}{\cL (p_1\nu \ \sigma)}
\\ \goodTerm{\Gamma, p_1\nu' \ \sigma}{p_2\mu \ o}{p_2\nu \ \sigma}
}
\quad 
\Rule[name=Lnkg Compile]
{ \goodTerm{\Gamma}{o}{\cL \sigma} 
}
{
  \goodTerm{\Gamma}{\cCt o}{\cC \sigma}
}
$$

$$
\Rule[name=Compile]
{}
{\goodType{\Gamma}{\cC \nu\cdot \equiv \top}{} 
\\ \goodTerm{\Gamma}{ \cCt \mu\cdot \equiv ()}{\cL \nu\cdot}
\\
\goodType{\Gamma}{\cC (\nu^+ \ \sigma \ \{f\} \ T) \equiv 
    \Sigma (\cC \sigma) T["sf" \ f]}{}
\\\\ \goodTerm{\Gamma}{\cCt \ (\mu^+ \ o \ \{f\}\ t) \equiv ((\cCt \ o), t["sf" \ f][(id, \cCt \ o)]) }{}
}
$$
% $$
% \Rule
% { \goodSeal{\Gamma}{f}{\sigma}{A}
% \\ \goodType{\Gamma, A}{T}{}
% \\ \goodTerm{\Gamma}{t}{T}
% }{}
% $$

$\goodSig{\Gamma}{\sigma}{n}$ means $\sigma$ is a well-typed signature
for linkages in the context $\Gamma$ with $n$ fields. We omit the
naming/label information for fields in the meta\-theory. The signature (for the linkage) and the linkage rules are quite similar to
the signature for inductive types.  They are both constructed from the
empty stuff, and respect substitution lemmas. We have
\ruleref{Sig Proj}, \ruleref{Lnkg Proj} projection for each component
due to harmony~\cite{pfenning2009lecture}, so we have local soundness
and local completeness ($\beta,\eta$ rules). We omit them and the
substitution laws for either field addition and projection. For
$\mu^+,\nu^+$ rules, we will omit the sealing $\{f\}$ if possible.\footnote{This
omission can be supported by Agda using Implicit Arguments}

A side note: before we dive in more details of our metatheory for linkage (especially the meaning of sealing and $\cC$), we have to mention that, the challenge of incorporating family polymorphism with inductive type mentioned in \ref{chg:extensible-inductive-type} mutates in metatheory because of de Bruijn indices. (Using surface synax), consider the example of a linkage $\{a~:~\bW \sigma; b_1 : a \to T;..\}$ with a bunch of $b_i$ \textit{using} $a$. The tension we need to solve here is between \textit{exhaustiveness checking} and \textit{inheritance (code reuse)}---on one hand, if we want to make sure $b_i$ is pattern matching correctly, then we have to construct $b_i$ term in the context of $a : \bW\sigma$; on the hand, if we want to let $b_i$ to be inherited into children family with extended inductive type $a~:~\bW \sigma'$, then the old inductive type $a~:~\bW \sigma$ in the context of $b_i$ is stopping that and thus we hope $b_i$ constructed in the context of $a : \cU$ (and thus later this $a$ can be compatible with inductive type of any signature). Our metatheory formulation of linkage is mainly trying to solve this tension.



We use $\cL$ to retrieve the corresponding types of linkage of a given signature, and $\cC$ to get the compiled linkage type (an existential type).
$\cL\sigma$ corresponds to the type of a family term, but $\cC\sigma$, according to \ruleref{Compile}, is a deeply nested dependent pair. Then $\cCt \sigma$ provide the concrete module of type $\cC\sigma$ given a linkage of type $\cL\sigma$. 

The reason we need this additional type construct of $\cC\sigma$ here is
to support \textit{code reuse}, as the rule of linkages hinders its
ability to do abstraction. Concretely speaking, (using surface syntax)
we don't have \\ $\goodTerm{\Gamma, \cL(\{a~:~\bW \sigma; b~:~a \to
T\})}{h}{\cL(\{a~:~\cU; b~:~a \to T\})}$\footnote{If we had one,
consider the case $T$ is bottom type and $\sigma$ is empty record and
thus $a$ is initially bottom type. Now the direct projection using
\ruleref{Sig Proj} $\goodTerm{\Gamma, a : \cU}{h.b}{a \to \bot}$ will
lead to problem because every field in linkage has this implicit
universal quantification, and for this case we can substitute $a$ with
arbitrary type, say $\top$: $\goodTerm{\Gamma}{h.b[a \mapsto \top]}{\top
\to \bot}$ is a contradiction}.
However, this underivable term is important for us to abstract the
concrete inductive type so that the later field can depend on the
``abstract interface'' (i.e. something like $\cL(\{a:\cU~;~b:a \to T\})$) and achieve \textit{code reuse}. 
\YZ{It reads as if you want to have 'h : L\{a : U, b : a -> T\}'. But it is problematic because it leads to inconsistency, as you describe in a footnote.}\EDJreply{Good point. I rephrased it so the introduction of sigma type is smoother. Please check.}
\\ The good news, we don't have to stick with $\cL(\sigma)$ to express the abstract interface. We can also use sigma type, and actually 
we do have $\goodTerm{\Gamma, (\Sigma a : \bW\sigma, a \to T)
}{h}{(\Sigma a : \cU, a \to T)}$ because of the rules for sigma type.\footnote{The intro rule for sigma type decides that there is no such implicit universal quantification happening.}
\YZ{This sentence still speaks of overriding. Explain in terms of projection instead?}\EDJreply{Fixed. Please check.}
Thus to allow abstraction happens, we need $\cC\sigma$ to compile a
linkage to module as a part of the context and we also need
\ruleref{Lnkg Compile} to specify the compilation from linkage to
module.


This is also reflected in the implementation of our plugin : we know every field is defined in the context of the former fields, but our implementation actually make every field dependent on \textbf{the compiled module of the already-defined-part of the family}. Thus we need $\cC\sigma$ in our context.
%\YZ{Why is Csigma needed? How is it different from Lsigma?}\EDJreply{It corresponds to the compilation of the family ``type'', which is part of the implementation detail. Basically we know every field of a family is dependent on the former fields. The implementation detail here is that, every field of a family is dependent on the compiled module of the former family (and thus includes all the former fields)}\YZreply{I don't think you should explain the metatheory from the angle of how things are implemented in your plugin. Rather, when describing your Coq plugin, you can say it matches the metatheory.
%PS: you use two terminologies: 'compile' and 'seal', but I guess they mean very similar things. So avoid saying 'compile' here.
%PPS: Sealing means hiding, so what is being hided? Why do you need to hide it? And how does the 'Compile' and 'Seal' rules perform hiding?}\EDJreply{  Compile is very different from seal.  Compile is making a linkage into a module, depriving the ability to override---if we understand a linkage as a module with a lot of universal quantifier inside. Compile cannot hide things, but only translate a linkage into a module. Seal is really something that does hiding---because existential type can hide stuff. Seal is an term between existential types. \\
%The ultimate reason we have this two notion is that, the introduction rule for linkage fails to provide abstraction mechanism so we have to translate them into module. \\
%Generally speaking Compile : Linkage -> Module, Seal : Module -> Module, we need module here because linkage cannot do abstraction of inductive type. A concrete detail is at the above. \\ 
%I now describe the motivation of compile in the earlier paragraph, right before the "reflecting" section. Note that, this compile is inspired by plugin implementation. This is the reason I say the metatheory is really close and inspired by the implementation. Similarly as I say ``there is no extensible inductive type but only overriding of new inductive type'' because in metatheory it is using overriding to ``extend'' (same as plugin implementation), seal means the same thing, and ``compile'' in metatheory happens in plugin implementation
%}

However, $\cC$ can only make sure we have $\cL(\{a~:~\bW \sigma; b~:~a
\to T\}) \to (\Sigma a:\bW \sigma, a \to T)$, we still need $(\Sigma
a:\bW \sigma, a \to T) \to (\Sigma a:\cU \sigma, a \to T)$ to complete
this shifting of the context. This is sealing's job.



\begin{figure}[H]

  \judgebox{[\goodSeal{\Gamma}{s}{\sigma}{A}] 
  = [\goodTerm{\Gamma, \cC\sigma}{s}{A[\pi_1]}] }
  $$
  \Rule[name=Seal Subst]
  {\goodSeal{\Delta}{s}{\sigma}{A}
    \quad {\goodSub{\Gamma}{\gamma}{\Delta}}}
  {\goodSeal{\Gamma}{s[\gamma]}{\sigma[\gamma]}{A[\gamma]}}
  =
  \frac
  {\goodTerm{\Delta, \cC\sigma}{s}{A[\pi_1]}
    \quad  \goodSub{\Gamma}{\gamma}{\Delta}  }
  {\goodTerm{\Gamma,\cC\sigma[\gamma]}{s[\gamma^\uparrow]}{A[\pi_1][\gamma^\uparrow]\equiv A[\gamma][\pi_1]}}
  $$
  $$
  \Rule[name=Seal-Id]
  {}
  {\goodSeal{\Gamma}{id_s}{\sigma}{\cC \sigma}}
  = \goodTerm{\Gamma, \cC\sigma}{\pi_2}{\cC\sigma[\pi_1]}
  $$

\medskip

\begin{minted}[escapeinside=@@]{agda}
Seal : (Γ : Con) → (σ : Sig Γ n) → (A : Ty Γ) → Set 
Seal Γ σ A = Tm (Γ, @$\mathcal{C}$@σ) A[π₁]

-[-]S : (f : Seal Γ σ A) → (τ : Tms Θ Γ) → Seal Θ σ[τ] A[τ]
f[τ]S = t[@$\tau^\uparrow$@]

idₛ : Seal Γ σ @$\mathcal{C}$@σ
idₛ = π₁
\end{minted}

\caption{Seal Judgement, and its Agda Representation (or What do we mean when we say one judgement is a shorthand for the other)}

\end{figure}


As we said earlier, $\goodSeal{\Gamma}{\_}{\sigma}{A}$ is actually just
a shorthand for term judgement $\goodTerm{\Gamma , \cC
\sigma}{\_}{A[\pi_1]}$,
a special form of \textit{local morphism}~\cite{abbott2003category}.
The substitution law should be understood as a lemma, and it is easily
derivable using $\gamma^\uparrow$. 

For notation clarity, we will sometimes use $"sf'"$ to emphasize
that we consider that seal $\goodSeal{\Gamma}{s}{\sigma}{A}$ as a term $\goodTerm{\Gamma, \cC \sigma}{sf'~s}{A[\pi_1]} $ and "sf" notation (used in \ruleref{Compile}) is defined as $\goodSub{\Gamma, \cC \sigma}{sf~s := (\pi_1, sf'~s)}{\Gamma, A}$.\YZ{What is sf and sf'? sf first appears in Compile rules, so explain sf there.}\EDJreply{Fixed. They both are explained at here now}

Sealing judgement is still about the important term $h$ we mentioned
earlier. Thanks to $\cC$, a field $t_{new}$ that depends on $a$ is now
in the context containing $\cC\{a : \bW \sigma; ..\}$.
But if we want $t_{new}$ to be inherited(reused) when $\sigma$ is
extended, we would like $t_{new}$ to be in the context containing
$\cC\{a : \cU; ..\}$ instead. The sealing is responsible for this
because we have a sealing $\goodTerm{\Gamma, \cC\{a : \bW \sigma;
..\}}{s}{\cC\{a : \cU; ..\}}$ = $\goodTerm{\Gamma, (\Sigma a : \bW
\sigma,..)}{s}{(\Sigma a : \cU,..)}$. Then we can construct
$t_{new}$ in the context containing $(\Sigma a : \cU,..)$, ready for
inheritance.
Apparently $t_{new}$ in this case cannot be doing \textit{exhaustiveness
checking}, but it can freely use any \textit{exhaustiveness-checked}
recursor.
%\YZ{It occurs to me that you use the word "sealing" to mean
%different (though tangentially related) things. Previously you used it
%as in "sealed families".}\EDJreply{They are actually the same thing.
%This sealing in metatheory is much stronger than that of the implemented
%plugin. Downside of the strong sealing is that if the user really use
%this version of sealing, the user will have to annotate what the sealed
%family type is. Now in the plugin, the sealed family type is almost
%fixed (directly inferred using a fixed rules). So basically this
%complete version of sealing (in metatheory) can deduce that of seal (in
%plugin implementation)}


% For example, $ X_1 : \bW
% \sigma_1 \vdash t : T$ in the parent family will generally not be able
% to be inherited to the children once we override the inductive type $\bW
% \sigma_1$ with $\bW \sigma_2$. 
% In
% other words, there is no way to ``transplant'' $t$ into the context $X_2
% : \bW \sigma_2$.
% This makes all the fields after this inductive type
% non-inheritable---which shouldn't be the case because a lot of fields
% might not be directly relying on this concrete $\bW \sigma_1$. 

% Sealing is used to exploit this fact---with sealing, given $X_1 : \bW
% \sigma_1$, we can add well-typed terms $X_1 : \cU \vdash t : T$, into
% the parent family. Later when we want to inherit $t$,
% because $t$ only consider $X_1$ as an arbitrary type, inheritance is
% possible. 

Now, together with sealing, we can read \ruleref{Sig Add} and \ruleref{Lnkg Add} out clearly: given a constructed linkage $o : \cL\sigma$ of signature $\sigma$, the next added field $t : T$ will have to be in the context of the abtraction $A$ of the compilation $\cC\sigma$ (witnessed by the seal $f$). The ``concatenation'' of the $o$ and $t$ leads to a new linkage, of which the signature is the ``concatenation'' of the $\sigma$ and $T$ (we also record the sealing $f$ for simplicity). The construction of linkage in \ruleref{Lnkg Add} requires $t$ to \textbf{only} refer to the (abstraction $A$ of) former part of the defining family $o : \cL\sigma$, this is to avoid inconsistency mentioned in \ref{chg:consistency} in metatheory.

This sealing is the general version of the sealed family implemented in the plugin. Our plugin will deduce a sealed ``interface'' for a sealed family using a fixed set of rules but here sealing in metatheory can be arbitrary local morphism. With the definition of sealing judgement in mind, we can see
\ruleref{Sig Add} and \ruleref{Lnkg Add} work exactly as the
implementation. In the implementation, we will have "self__" all around
when defining new fields in our plugin, and this "self__" is exactly the
$A$ in the context of the two fields---in our implementation, there is only sealing of inductive type happening (where each inductive type we only know \mintinline{Coq}{T : Set}).

In summary, with the help of both sealing and $\cC$, we can shift the context from $\cL(\{a~:~\bW \sigma; ..\})$ to $\Sigma a : \cU,..$ and thus achieve code reuse. However, this is just allow possible \textit{code reuse}, we still need to solve the mutated tension in \ref{chg:extensible-inductive-type}. To make things concrete, we need to introduce the rules for recursors.

% Since our recursor handlers are closely related to linkages, we can finally talk about the rules of recursor now. 

$$
\Rule[name=Hdler]
{\goodType{\Gamma}{A}{}
\quad \goodType{\Gamma, A}{B}{}
\quad \goodType{\Gamma}{R}{}
}
{\goodType{\Gamma}{"RecSig1"~A~B~R \equiv (\Pi A (\Pi (\Pi B (R[\pi_1\circ\pi_1])) R[\pi_1\circ\pi_1]) )}{}}
\quad 
\Rule[name=Hdlers]
{\goodWSig{\Gamma}{\sigma}{n}
\quad \goodType{\Gamma}{R}{}
}
{\goodSig{\Gamma}{"RecSig"~\sigma~R}{n}\YZ{Why does this Sig not have a superscript?}\EDJreply{Fixed now.}}
$$
$$
\Rule[name=Hdler-Proj]
{ \goodWSig{\Gamma}{\sigma}{N}
\quad \goodTerm{\Gamma}{o}{\cL("RecSig"~\sigma~R)}
\quad n < N
}
{\goodTerm{\Gamma}{"prjR"~n~o}{("RecSig1"~(\pi_1^n \sigma)~(\pi_2^n \sigma)~R)[\pi_1]}}
$$
$$
\Rule[name=Rec-Constr]
{ \goodWSig{\Gamma}{\sigma}{N}
\quad \goodType{\Gamma}{T}{\bW \sigma}
\quad \goodType{\Gamma}{R}{}
\quad \goodTerm{\Gamma}{r}{\cL("RecSig"~\sigma~R)}
\quad \goodTerm{\Gamma}{w}{El~("W"~T)}
}
{\goodTerm{\Gamma}{"Wrec"~r~w}{R}}
$$

In our meta-theory, we only formulate non-dependent eliminator for simplicity, i.e., the
\textit{recursor}.\YZ{Do dependent eliminators pose technical difficulties, or do you avoid them solely because they require more verbiage?}\EDJreply{I don't think there is technical difficulties to do that. The formulation of course will be much more horrifying if use dependent eliminator here. } 
Each recursor is constructed by a linkage containing
functions/handlers/pattern-matching cases dealing with each
constructor. Thus code reuse for recursor is delegated to linkage
inheritance---to reuse one particular pattern-matching case,
we just inherit the function/handler. This greatly simplifies the
metatheory development.

Intuitively \ruleref{Hdler} is indicating the type of recursor handler
for one specific constructor, and \ruleref{Hdlers} is the linkage type
of the bundle of all recursor handlers of one given inductive type. We
omit the definition of "RecSig" but \ruleref{Hdler-Proj} indicates its
(apparent) internal definition. "prjR" is also the handler selection
from the handler linkage, and is helpful for the formulation of
$\beta$-rule of "Wrec" (omitted here). Finally \ruleref{Rec-Constr} is
used to construct a concrete recursor given a specific linkage of
handlers. All these rules satisfy substitution laws and omitted here.


Again, we still use \textit{decoupling} of the syntax of the case
handlers and exhaustiveness checking to resolve
\ref{chg:extensible-inductive-type}. We use linkages to define
case handlers and thus they are inheritable like other families.
While any field using "Wsup" and "Wrec" directly relies on the
$\bW\sigma$ (can be spotted from \ruleref{Ind-Term} and
\ruleref{Rec-Constr}) and thus non-inheritable---in these cases, "Wsup"
can be understood as concrete constructors and "Wrec" are
\textit{exhaustiveness checking}. These fields together with inductive
types are the ones sealing is responsible for hiding. After compilation
of linkage types into existential types, we can easily hide the
\textit{concrete} definition of the inductive type while exposing all
the fields using "Wsup" and "Wrec" like an abstract interface.
Apparently, future fields relying on this abstract interface will have no
problem on inheritance.
Of course, since "Wsup" and "Wrec" directly rely on the concrete inductive definition, we will have to override these fields whenever inductive type is overridden. For "Wsup" we only need to override each constructor and for "Wrec" it is just doing exhaustiveness checking inside each children family. The recursor handlers however, can be safely inherited.
\YZ{I suppose the terminology 'sealing' is a reference to ML modules? In
ML, sealing has the connotation of hiding things behind an existential
type. So using the same word may cause the reader to have false
presumptions about what is going on here.}\EDJreply{You are right. Our "Sealing" is not hiding a particular field into an existential type, but our seal is make several fields together into an "existential type". Basically it hides the concrete definition of inductive type so that future fields doesn't have to be defined upon that.}\EDJreply{I will resolve this comment once I add the throughout example and you find it clear---because I haven't changed any text}

There are also cases we don't need to seal anything (i.e., for doing
exhaustiveness checking when using recursor), and thus \ruleref{Seal-Id} is
used. 





Next we talk about inheritance judgement. Note that, there will be a lot of $\sigma_1, A_1$ and $\sigma_2, A_2$, and in these cases, $A_1$ is the result of the sealing of $\sigma_1$, i.e. we assume we have a term $\goodSeal{\Gamma}{f_1}{\sigma_1}{A_1}$, $\goodSeal{\Gamma}{f_2}{\sigma_2}{A_2}$ in the assumption of judgements when needed.


\judgebox{\goodInh{\Gamma}{h}{\sigma}{\tau}}

$$
\Rule[name=Inh-Id]
{}
{\goodInh{\Gamma}{"inhid"}{\sigma}{\sigma}}
\quad
\Rule[name=Inh-Override]
{
\goodInh{\Gamma}{h}{\sigma_1}{\sigma_2}  
\quad \goodType{\Gamma, A_1}{T_1}{}
\quad \goodType{\Gamma, A_2}{T_2}{}
  \quad \goodTerm{\Gamma, A_2}{t}{T_2}}
{\goodInh{\Gamma}{"inhov" \ h \ t}{(\nu^+ \  \sigma_1 \  T_1)}{(\nu^+ \  \sigma_2\  T_2)}}
$$

$$
\Rule[name=Inh-Ext]
{\goodInh{\Gamma}{h}{\sigma_1}{\sigma_2}
  \quad \goodTerm{\Gamma, A_2}{t}{T}}
{\goodInh{\Gamma}{"inhext" \ h \ t}{\sigma_1}{(\nu^+ \  \sigma_2\  T)}}
\quad
\Rule[name=Inh-Inh]
{\goodInh{\Gamma}{h}{\sigma_1}{\sigma_2}
\quad \goodType{\Gamma, A_1}{T}{}
\quad \goodTerm{\Gamma, A_2}{\uparrow^s}{A_1[\pi_1]}
}
{\goodInh{\Gamma}{"inhinh" \ h}{(\nu^+ \  \sigma_1 \  T)}{(\nu^+ \  \sigma_2 \  T[(\pi_1, \uparrow^s)])}}
$$
$$
\Rule[name=Inh+Inh]
{\goodInh{\Gamma}{h}{\sigma_1}{\sigma_2}
\quad \goodTerm{\Gamma, A_2}{\uparrow^s}{A_1[\pi_1]}
\quad 
\goodInh{\Gamma, A_2}{i}{\tau_1[(\pi_1, \uparrow^s)]}{\tau_2}}
{\goodInh{\Gamma}{"inhnest" \ h \ i}{(\nu^+ \  \sigma_1\  \cL\tau_1)}{(\nu^+ \  \sigma_2\  \cL\tau_2)}}
\quad
$$

$$
\Rule[name=Inh]
{\goodInh{\Gamma}{h}{\sigma_1}{\sigma_2}
\quad \goodTerm{\Gamma}{l}{\cL \sigma_1}
}
{\goodTerm{\Gamma}{("inh" \ h \ l)}{\cL \sigma_2}} 
\quad 
\Rule[name=Inh-Inh-beta]
{\goodInh{\Gamma}{h}{\sigma_1}{\sigma_2}
  \quad \goodTerm{\Gamma}{m}{\cL \sigma_1}
  \quad \goodTerm{\Gamma, A_1}{t}{T}
}
{\goodTerm{\Gamma}{"inh" ("inhinh" \ h) (\mu^+ \ m \ t) \equiv \mu^+ \ ("inh" \ h \ m) \ t[(\pi_1, \uparrow^s)]}{}} 
$$

Inheritance are
judgement so naturally second class citizen data (i.e. not something
function can return and cannot be assigned to variables), and it looks
very much like a function that transform a given linkage. Similar to plugin implementation and \ruleref{Lnkg Add}, we resolve \ref{chg:consistency} by making sure corresponding fields are in corresponding context during inheritance, and thus an overriding term can only refer to fields before the overriden field. 

The syntax of the inheritance judgement is very close to how Family is
defined in the surface syntax---a Family with no parent is an
inheritance with empty input; an extended Family is exactly an
inheritance---because the parent of an extended Family can be overridden
thus inheritance should only define upon the ``interface'' instead of a
concrete family. However, since our current formulation doesn't support
nested inheritance (i.e. we cannot do inheritance inside a family but only top level), our
formulation still has some distance to the real family polymorphism. 

"inhid" and "inhext" are simple as expected---the former corresponds to
empty inheritance, and the latter gives the programmer the ability to
add new fields.

"inhinh" is special because it requires user to provide a proof of
``upcasting'' from the context of the child to that of the parent.
In other words, if I want to inherit a specific field from the parent, I
have to convince the type checker that my current context can
``accommodate'' the inherited field. 

Override "inhov" is even more special because in mundane OO programming language, we usually require that the overriding term has the same type/interface as the overriden one.  Here we don't since the very reason we want the same type/interface is that we hope other inherited fields can use this overridden/late-binding field without breaking abstraction, and this reason is already managed by the assumption of "inhinh", the upcasting proof $\uparrow^s$. Thus "inhov" is quite like "inhext", where overriding is just throwing away one parent field. This difference also show one of the distinct feature of our vanilla family inheritance compared to the mainstream OO inheritance---family inheritance don't need to introduce the concept of ``subclassing'' between families and thus no bounded polymorphism yet\footnote{Of course once trait and interface comes in, we can have bounded polymorphism back}, and code reuse is mainly achieved by late binding. Without ``subclassing'', there is no way of confusing inheritance and subtyping. Note that, "inhov" is also responsible for ``extending'' inductive type---the extended inductive type directly override the old ones when using metatheory to program, just like how plugin implementation works.

Finally we need to introduce nested inheritance "inhnest" for dealing with nested families. The rule is mostly direct and we need "upcasting" again when dealing with nested family in different but inheriting context.  We also show how to use an inheritance judgement to derive children family and how the beta rule is defined. We omit most of the other substitution laws here.



\subsection{Exemplar Usage of Meta Theory}
\input{syntactic-example.tex}