
% \subsection{Language Design}


% \subsection{Plugin Implementation}

In this section, we describe how we can implement the proposed Vernacular commands.

After considering the pros and cons, we decide to implement a Coq Plugin where we can add new Vernacular commands and translate each new command into a bunch of Coq commands (the orignal surface Vernacular command) on the fly, instead of modifying the code-base of Coq. 

Despite possible difficulties for future maintenance, this approach has
various advantages: 1. it is the easiest and the most accessible way to
prototype as it relieves us the necessity of familarity of Coq base,
especially for the implementation of the module and functor; 2. we have
a clear definition of trusted-base---the whole Coq; 3. it is easy to
debug---we just need to check the translated commands; 4. it can be
well-incorporated with the existent tools like VSCoq; 5. it is more
accessible for the interested audience who can then easily adapt our
plugin and give a try---otherwise they have to download and re-build the
whole customized Coq; 6. it is more stable because the surface syntax of
Coq should be stable across different versions; 7. still, this plugin
can capture the key ingredients of implementing family polymorphism
inside Coq and act as a reference for guiding an appropriate
implementation of Family Polymorphism inside all sorts of proof
assistants.\YZ{Does the Coq implementation perform type checking to
prevent illegal uses fam poly?}\EDJreply{Yes. Because I define feature of fampoly as a direct translation into Coq feature.  The fampoly is like a shorthand into multiple Coq commands. \\
Do you find translation from my current metatheory into MLTT (without linkage) helpful? \\
Actually I am also not sure what this question is aiming towards. \\
Are you complaining there is no formal specification of my fampoly feature in paper and thus there is no proof my Coq surface syntax is related to metatheory? If so, I thought our Coq plugin is only advertising how powerful Fampoly is to solve expression problem in mechanized proving. I can decouple the relationship between our plugin and our metatheory if you find the gap is really there... And I can only claim metatheory is about a partial result on incorporating fampoly with dependent type, Coq plugin is using two example to illustrate how mechanized proving can get benefit and our Coq plugin is only inspired by our metatheory (and not claim any relationship). Doing so would require rearrange the metatheory section before this section. \\
But I don't think the gap is there at all because if you want all possible gaps to disappear, then the action of using debruijn is wrong because we need to prove the one using debruijn and the surface syntax that is not using debruijn are ``equivalent''. What's more, module is not sigma type because Module is not a term in Coq and thus there is no formalism of Module at all. Let alone I don't see the plausibility of mechanizing dependent type without debruijn. \\ 
Please comment back so that I know what corresponding modification is needed on the paper. 
}\YZreply{My original question was more directed towards the fact
that currently type checking is deferred to the Coq base. Generally,
when one uses a statically typed language as a compilation target, they
also want to have type checking at the source level, (1) because there
could be type errors at the source level that could not otherwise be
caught at the target level and (2) because it allows better error messages.
So it needs to be addressed why deferring type checking to Coq is OK.}\EDJreply{Good point. I think (1) is largely mediated by the fact the semantic of family is very close to that of the module. And the supporting feature is simple enough that there won't appear some problems like type error at source-level but not target level(2) is happening for sure but some basic error message is almost "transparent" i.e. the error-messages from Coq can be directly interpreted for the user. But my justification is solely empirical and as you know the empirical study for this paper is not really strong enough to support anything.}


\textbf{Family compiled into module.} The main idea of our plugin is to support family by compiling
family components into Coq modules, family ``types'' into module types, and the context of a given term
into parameters of the module. We need to faithfully
reflect the \textit{late binding} nature of families: for each defining
field $ .. \cL\sigma \vdash t : T $, we need to compile $t$ using
``universal-quantifier-wrapped term'' : $.. \vdash \lambda t : \forall
\cL \sigma. T$. However, instead of using Coq's universal quantifier, we
choose module and module parameters to achieve this wrapping---each
family type in the context will be one module parameter
with the compiled module type, and thus each field of the family will
compile into a functor parametrized by its context. Doing so we can also
get rapid feedback from type checking when the users are defining each
field interactively with Coq.
% Insert one pseudo-code example for explanation of the mechanism
\begin{figure}[!htb]
  \begin{minipage}[t]{0.30\linewidth}
\begin{lstlisting}[language=Coq, escapeinside={@}{@}]
Family A.
Field a : nat := 1.
Field b : a = a := eq_refl.
Final Field a' : nat := 1. 
EndFamily.
\end{lstlisting}
  \end{minipage}%\YZ{Can the self's be omitted?}\EDJreply{Yes. But in our current plugin implementation it is not omitted. I think altering example is fine. If you think some small distance between example and the current implementation is fine, please comment back and I will remove all the self_}\YZreply{If omitting the self's poses no technical challenges, then I'd say it's fine to also omit them in this figure.}\EDJreply{Omitting self_ is easy and not much engineering effort is required. But omitting self_ will lead to `A.a' instead of `a' actually. So if we really want `a' as you last time mentioned, then a resolution is required and more engineering effort is required. But I don't see any technical difficulties. I have removed all the self, please check.}
  \begin{minipage}[t]{0.35\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Module a_4 (self_A: EmptySig).
Definition a : nat := 1. End a_4.
Module Type a_5 (self_A: EmptySig).
Parameter (a : nat). End a_5.
Module Type a_6 := a_5 EmptyMod.
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.3\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Module b_7 (self_A: a_6).
Definition b 
  : self_A.a = self_A.a 
  := eq_refl. End b_7.
  
Module A. (* Final Aggregation *)
Include a_4. Include b_7. End A.
\end{minted}
  \end{minipage}
  \caption{Example Code and Plugin Translation}\label{fig:plugin-example1}
\end{figure}


% Concrete details of compilation of a family term data structure
Taking \cref{fig:plugin-example1} as an example: immediately after the user inputs the line "Field a : nat := ..", our plugin will
translate this statement into the "Module a_4", "Module Type a_5, a_6"
three components.
{The "EmptySig" is just an empty module type.} Then,
these modules and module types will be generated and type-checked by Coq
immediately. The compiled "Module a_4" is then part of the context of
"Field b" (as the module type of "self_A") for "b" to refer to. The
internal representation of family "A" is the list of these
compiled modules and module types. We can achieve incremental
checking as in \ref{chg:software-engineering}; overriding is also directly supported---for example, if we
want to override "Field a", we simply replace that compiled module with
the new module inside the list. This compiled module type serves as an
abstraction that enables overriding. 



This is achieved by a complete compilation from a family to a module,
via aggregating the list of the modules in the internal representation:
the plugin will repeatedly using Coq's "Include" command as the "Module
A" as \cref{fig:plugin-example1} illustrates.
References to family "A" outside "A" will be compiled to references to
this Coq module "A".

Note that, in our example, we include two
functors without arguments---this is due to a peculiarity of Coq's
"Include": uninstantiated parameters will be automatically
instantiated by the appropriate fields in the surrounding defining
module.
For example, "b_7" requires a module of type "a_6". Inside module "A",
when "Include a_4" is done, we will have a field \mintinline{Coq}{a : nat}
inside the current surrounding "A". Then when we
\mintinline{Coq}{Include b_7} without specifying the module parameter,
Coq will try to find fields in the surrounding module (i.e., module
"A") to instantiate \mintinline{Coq}{self_A: a_6}. This is satisfied by
the \mintinline{Coq}{a : nat} that is included earlier.
The resulting compiled module is just like mundane Coq's module and 
thus maintains all the computational mechanism from Coq, fulfilling
requirements in \ref{chg:software-engineering}.\YZ{
  Do I understand correctly that an alternative to individually
  compiling family members to modules is to compile a family as a whole,
  but this alternative would not satisfy the "incremental type checking"
  or "instant feedback" requirement?
}\YZreply{
  Looks like individually compiling family members addresses not only
  this requirement, but also the "self vs. consistency" challenge.
}



% explaining inheritance
\textbf{Implementing Inheritance.}
To simplify the implementation, we can consider all families as
inheritance and the standalone families are extending the empty family.
Thus, we need to deal with only inheritance during interactive theorem proving.


Simiarly, we
use a list to encode the three kinds of inheritance data in the
implementation. The inheritance data will include the
information of (1) the ``type'' of the parent family, (2) a list of
operation indicating how each field of the parent will be dealt with
(either inherited or overriden), (3) the operations indicating newly
extended fields, and (4) the ``type'' of the children family.
The surface syntax for the three kinds of inheritance
are demonstrated in the exemplar \cref{fig:plugin-example3}. The
implementation of overriding, inheritance, and extension is achieved by
simply manipulating the internal representation of a family
correspondingly---we can swap the module in the list for overriding,
retain the module in the list for inheritance, and add new module into
the list for extension. The compilation from a family (internal
representation) to a module still acts the same.

Though inheritance is solely a first-order data rather
than a ``mapping'', it is still possible to \text{mixin} two inheritance
data---by carefully ``mix'' the internal list, we can compose the
inheritance. However, a good definition of mixin is still under
investigation. We will show one practical example of \textit{mixin}
later.\YZ{How about making mixin composition one of your Req's? Also
does any example in the paper illustrate how to do this?}\EDJreply{mixin
is not really formalized. There is no example illustrate it. The only
example is the STLC example at the very end and I just kind of
``mention'' it. I think here I just want to emphasize, inheritance as
first order data is still possible to support composition.}

Our implementation also makes sure the first attempt of defining "c"
failed successfully in \cref{fig:plugin-example3}---proving "c"
would require a concrete definition of "a", and our plugin rejects
\mintinline{Coq}{c : a = 1 := eq_refl} in a context where we
only know \mintinline{Coq}{a : nat}.



\textbf{Implementing "Final" and "Sealed Family".}
We implement "Final" by
exposing the whole definition directly into the compiled module type.
Doing so will prohibit overriding. Say, "bop", declared "Final" in
\cref{fig:plugin-example3}, is not overridable.
We require the users to manual decorate field as `Final' so that the
plugin will proceed with this special treatment.
%\YZ{This para is confusing: which kind of equality is used, propositional or judgmental? Where does 'Final' show up in the example?}\EDJreply{I rephrase it and remove the part on talking about meta-theory. Now everything is about judgemental so I don't have to emphasize judgemental. I wanted to make the example small but I guess I can add one `Final' statement into our example. Don't resolve it until I add it into Figure 2.}

% \textbf{Special Fields: Overridable/Sealed Family Simulating Sigma Type.} 

The implementation of sealed family is not so different from that of the normal family, but we need to deal with the compiled module type. The compiled module type is the aggregation of the type instead of the concrete definition of the fields.
For example, the compiled module type of
"MonotonicF" in \cref{fig:plugin-example3} will be "{f : nat -> nat; p : monotonic f}". Thus any future overriding family will always have these two fields "f, p" with the corresponding type.\YZ{Can an overriding, sealed family define new fields not in its parent?}\EDJreply{I don't find this a problem but I didn't support it in my plugin. }


% Basically, {a : int -> int; property : a is monotonic}, in this case
%   we may want to override "a" using different computation, but we still wnat
%   this refinement/property




\textbf{Special Fields: ``Extensible'' Inductive Type and Defining Recursor.}
We support extensible inductive types in Coq mentioned in
\ref{chg:extensible-inductive-type}, but we will not be aiming at the
research of its formal semantic.\footnote{Because to give a satisfactory
formal definition and semantic for extensible inductive type is not
something this paper aims at, and obviously requires more theoretical
research effort}
%\YZ{I do consider that your plugin supports extensible inductive types. It's just that they are implemented as a plugin, rather than in the Coq core.}\EDJreply{I rephrased it. It is more like I don't think this is really the final form of extensible inductive type that everyone is happy about}

% \begin{figure}[!htb]\YZ{Change this one into STLC example, to see the layout}
%   \begin{minipage}[t]{0.32\linewidth}
% \begin{lstlisting}[language=Coq,  escapeinside={@}{@}]
% Family B.
%   FInductive b : Set 
%     := tt : b | ff : b.
%   Family neg_handler. 
%     Field tt : self_B.b 
%       := self_B.ff.
%     Field ff : self_B.b 
%       := self_B.tt.
%   EndFamily.
%   FRecursor neg 
%     about self_B.b 
%     motive (fun _ => self_B.b)
%     using self_B.neg_handler
%     by _rec.
%   Field example := 
%     self_B.neg self_B.tt. 
% EndFamily.
% Family B2 extends B.
%   Extend FInductive b : Set 
%     := uu : b.
%   Extend Family neg_handler.
%     Field uu : self_B2.b 
%       := self_B2.uu.
%   EndFamily. 
% EndFamily.
% \end{lstlisting}
%   \end{minipage}
%   \begin{minipage}[t]{0.65\linewidth}
% \begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}
%   (* Abstraction for Inductive Type *)
% Module Type b_3 (self_B: EmptySig_4).
% Parameter (b : Set). Parameter (tt ff : b). End b_3.      
% Module Type b_6 := b_3 EmptyMod.
%   (* Recursor to Set for b *)
% Module b_rec_12 (self_B: b_6).
% Definition __recursor_type_b_rec :=
%   forall P : self_B.b -> Set,
%   P self_B.tt -> P self_B.ff 
%   -> forall __i : self_B.b, P __i. End b_rec_12. 
%   (* Field B.neg_handler.ff *)
% Module ff_24 (self_B: b_6) 
%              (self_neg_handler: tt_23 self_B).
% Definition ff : self_B.b := self_B.tt. End ff_24.
%   (* Intermediate Module solely for type checking *)
% Module v_33_34 (self_B: neg_handler_26).
% Include b_rec_12 self_B.
% Parameter (recursor_for_type_checking : __recursor_type_b_rec).
% Definition term_for_type_checking :=
%   recursor_for_type_checking (fun _ : self_B.b => self_B.b)
%     self_B.neg_handler.tt
%     self_B.neg_handler.ff.  
% End v_33_34.
% \end{minted}
%   \end{minipage}
% \caption{Example Code for Inductive Type}\label{fig:plugin-example2}
% \end{figure}


\begin{figure}[!htb]
  \begin{minipage}[t]{0.32\linewidth}
\begin{lstlisting}[language=Coq,  escapeinside={@}{@}]
Family STLC.
(* ... *)
  Family subst_internal. 
  Final Field tm_var : ...
:= fun s x t => 
    if (eqb x s) 
    then t else (tm_var s).
  Final Field tm_abs : ...
:= fun s (b : tm)   
   (recb : id → tm → tm) 
   x t => 
    if (eqb x s) 
    then (tm_abs s body)
    else (tm_abs s (recb x t)).
(* ... *)
  EndFamily.
  FRecursor subst 
    about tm 
    motive (fun _ => id → tm → tm)
    using subst_internal
    by _rec.
(*
Field test := (subst (tm_var 0) 0 (tm_var 0)).
*)
(* ... *)
EndFamily.
Family STLC_bool extends STLC.
(* ... *)
Extend FInductive tm : Set :=
  | tm_true : tm ...

Extend Family subst_internal.
Final Field tm_true : ...
  := fun x t => tm_true.
(* ... *)
EndFamily. 
Inherits subst.
(* ... *)
EndFamily.
\end{lstlisting}
  \end{minipage}
  \begin{minipage}[t]{0.65\linewidth}
\begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}

Module Type STLC_409.
  Parameter (tm : Set).
  Parameter (tm_var : id → tm).
  Parameter (tm_abs : id → tm → tm).
  (* ... and all the fields defined before
  and the abstraction for inductive type ...*)
End STLC_409.
(* Collect eliminator to Set for tm *)
Module tm_rec_425 (STLC: STLC_409).
  Definition __recursor_type_tm_rec :=
    forall P : STLC.tm -> Set,
    (forall n : id, P (STLC.tm_var n)) ->
    (forall (n : id) (i : STLC.tm),
    P i -> P (STLC.tm_abs n i)) ->
    ... -> forall i : STLC.tm, P i.
End tm_rec_425.
(* Compiled Field STLC.subst_internal.tm_var *)
Module tm_var_411 (STLC: STLC_409)
  (subst_internal: EmptySig).
  Definition tm_var :
    forall (s : id) (x : id) (t : STLC.tm), STLC.tm :=
    fun s x t ⇒ if eqb x s then t else STLC.var s.
End tm_var_411. (* ... and more *)
(* Aggregate into one subst_internal*)
Module subst_internal_410 (STLC: STLC_409). 
  Include tm_var_411 STLC. (* And other cases ... *)
End subst_internal_410.
Module v_33_34 (STLC: STLC_409).
(* Intermediate Module solely for type checking *)
  Include tm_rec_425 STLC.
  Parameter (recursor_for_type_checking : __recursor_type_tm_rec).
  Definition term_for_type_checking :=
    recursor_for_type_checking (fun _  ⇒ id → STLC.tm → STLC.tm)
      subst_internal_410.tm_var
      subst_internal_410.tm_abs ... .
End v_33_34.
\end{minted}
  \end{minipage}
\caption{Exemplar STLC Code, especially about Inductive Type}\label{fig:plugin-example2}
\end{figure}



% We start with the programming interface. We use "FInductive" to define an extensible inductive type and in the children family we use "Extend Finductive ..." to extend the type with new constructors. In \cref{fig:plugin-example2}, we make the example of boolean and three-valued boolean. 



% Recall, to construct a recursor, we need to create for each
% constructor a handler (function) and aggregate them into a family (e.g. "subst_internal" in \cref{fig:plugin-example2}). We use "FRecursor" to declare a recursor (e.g. "subst") by specifying the motive, the aiming inductive type and the handler family. Once recursor is created it will look like any other function fields (e.g. "subst"). Here in \cref{fig:plugin-example2} we can apply the function "subst" to "tm_var 0" as a new field. The inheritance of recursor is mainly delegated by the inheritance of the handler family---if the user extend with new constructor (e.g. "tm_true"), then the inherited family (e.g. "subst_handler") will need to extend correspondingly (e.g. "subst_internal.tm_true"). If not, the plugin will error with ``Non-exhaustiveness Pattern'' when inheriting the field "subst".\EDJ{This paragraph is duplicating but I am not sure how to make it concise.}



Let's look at the exemplar \cref{fig:plugin-example2}, the example of
"subst" on STLC. When we define the extensible inductive type "tm", all
the following fields (e.g., "subst_internal.tm_var") can only know "tm"
is a type (of "Set") and there are at least two constructors for it,
just like what we declare in ``the abstracted interface''---the compiled
module type "STLC_409". We cannot export
%\YZ{export or put?}\EDJreply{Ok.
%I just figure out how my wording is confusing. put is absolutely correct
%but by put I want to mean ``export''. I think I use ``export'' in
%several places...}
the eliminator of the inductive type "tm" to "STLC_409".
Otherwise all the subsequent fields (e.g. "subst_internal.tm_var" and
the corresponding "tm_var_411") would not be able to be inherited to the
context where "tm" is extended with a third constructor, \textbf{since
the mere existence of the recursor will assert that there are only two
constructors} in "STLC_bool", not \textbf{extensible} at all!

However, we later still need the concrete eliminator on "tm" for doing
exhaustiveness checking (as in \ref{chg:extensible-inductive-type}),
thus we will store the corresponding info somewhere.  Here we show one
exemplar extraction of the eliminator to \mintinline{Coq}{Set} as module
"tm_rec_425". This concrete eliminator will be used by our "FRecursor".
For example, in \cref{fig:plugin-example2}, "FRecursor" command will
feed Coq a module "v_33_34" for doing type-checking with specified
handlers (e.g. "neg_handler") during compilation---what it does is
basically
assert the existence of the recursor and apply to see if handlers can
pass the type checking by Coq.\YZ{
  Sounds like we can still claim the plugin is doing type checking.
  It's just that the checking is done by generating some Coq code and
  then having Coq check it.
}
Note that, at this point of the example,
"FRecursor" will only do type check. The compilation of "FRecursor" into
a component of the compiled module only happens when closing the whole
family, by inserting the following into the compiled module: 
\begin{minted}{Coq}
Definition subst := tm_rec (λ _ ⇒ id → tm → tm) subst_internal.tm_var ...
\end{minted}
where "tm_rec" and "tm" are the corresponding recursor and
the (vanilla) inductive type in that compiled module. Thus a "FRecursor"
field is unlike other fields, even though it is exposed as a mundane
function for the following fields in the programming interface.\YZ{
  Why is this special treatment needed for compiling FRecursor?
}

The plugin actually realizes the "Extend FInductive" via overriding---%
when extending an inductive type $A$ with new constructor $c$, our
plugin will generate a new (syntactic) inductive definition $A'$ with
this new $c$ on the fly and feed it to Coq. But we must be careful on
the exposing data in the family type (the compiled module type) for the
following field. In other words, we must be careful on what interface
(context) the following fields are defined based on. 

Importantly, the recursor field (e.g. "subst") is not actually
inheritable, because it is not compiled like any other fields.
Recall how other fields are compiled into reusable pieces of
(parametrized) modules; a recursor field is not compiled like that.
For all the children family, we have to reconstruct and override the
"FRecursor" field with a ``new'' recursor using (maybe the same) handler
family.  This is affordable since each aggregated recursor handler
doesn't need to be rechecked---look at "STLC_bool.neg_handler", there
are only  new handlers for "tm_true" and the handlers (mundane fields)
from the parent "B.subst_internal.tm_var" have already been type-checked
and inherited (since they only rely on ``the abstracted interface''
module "STLC_409"). 
Thanks to family inheritance, their corresponding compiled module from the parents---for example, 
the module "tm_var_411"---doesn't require another type-check and is
re-used during the type-checking and compilation of "STLC_bool.subst".
For example, for the new "subst", when compiling family "STLC_bool" into
a module, at the appropriate place our plugin will insert
\begin{minted}{Coq}
Definition subst := tm_rec (λ _ ⇒ id → tm → tm) subst_internal.tm_var ...
\end{minted}
where "tm_rec" and "tm" are the corresponding recursor and the (vanilla
but extended and modified) inductive type in that compiled module. Note
that, even though "tm_rec" and "tm" has the same name as before, they
are in the newly-compiled module so they refer to totally different
things. 





Of course, in the implementation, our plugin will ``inherit'' the
recursor "neg" in the surface,
but what the plugin actually does is doing a second exhaustiveness
checking in children family like mentioned above, with the ``same'' motive and the ``same'' handler family.
%\YZ{A source of confusion in this section is that the reader often has to guess who performs the actions: is it the programmer or the Coq plugin?}\EDJreply{Good idea. Let me reorgnaize this section to ``first programming interface'', then ``plugin implementation''}



 

% Insert one pseudo-code example for explanation of the mechanism
% Use the natural number example




% Explain why the module type need extra care

% explain how recursor is constructed
% explain we have the incremental-checking for any recursor 

% explain ftheorem wrapping this complicated recursor
This design of decoupling of the case handlers and exhaustiveness checking handles the semantic well, however, it brings a lot of boilerplate code---we need to create an extra (handler) family, manually specifying the type of each case handlers, and then using "FRecursor" to ``tie the knot'' and construct a recursor field from the handlers.  
We thus provide a command "FTheorem" to avoid these boilerplate in programming interface when using tactic programming. 
This command (1) can avoid specifying the handlers family and the type of each case handlers when writing induction like above, (2) invoke
proof interaction mode and thus allow tactic programming, (3) and is also open to extension like "FRecursor".\YZ{example?}\EDJreply{FTheorem is really just a short hand for "FRecursor" + handler family. Nothing more conceptual here. If the reader is interested in the concrete syntax, I think I need to make the two examples avaliable in the appendix.} We expect this "FTheorem" to be used in theorem proving but not general programming. 

To summarize, (1) to make each recursor
handler inheritable, we need to seal an abstraction around the inductive
type (e.g., module "b_3"); but to construct a recursor (and carry out the
exhaustiveness checking), we need to break this abstraction and see the
concrete definition of the inductive type (e.g., module "b_rec_12"). Our
meta-theory need to handle these two seemingly contradicting ideas
simultaneously when solving \ref{chg:extensible-inductive-type} . (2) \ref{chg:extensible-inductive-type} is also resolved by this \textit{decoupling} of the syntax of implementation of recursor handlers and exhaustiveness checking. The former is handled by family inheritance and thus avoiding the boilerplate code; and the non-inheritance of the compiled recursor ensures the exhaustiveness checking happens for every recursor.  


% Mention still needing total recursor, for exhaustiveness checking

\textbf{Hack: Global Reasoning.}\YZ{This is more like an escape hatch. Escape from family poly into vanilla Coq. Maybe these two hacks should be grouped into one section}
% explain the places using ``Closing Fact''
% 1. No need to export partial recursor
% 2. Computational rule for the total recursor
Unfortunately, there are cases an extensible proof brings more boilerplate code. For example, in STLC, we expect
``\mintinline{Coq}{~ value (tm_app x y)}'' to hold in all future
extensions of STLC---applications will never be considered as values
by any extension.
We know the correct way to prove the proposition
\mintinline{Coq}{value_not_app : value (tm_app x y) -> False.} is to use
"FRecursor" to inductively reason "value (tm_app x y)". However, this
means that every time we extend "value" with new value forms, we will
need to extend corresponding inductive cases for "app_not_value". We can
imagine the newly extended proof to be boring case analysis that the
newly added value forms are not "tm_app". What's worse, similar
scenario can happen on other statements like \mintinline{Coq}{~ value
(tm_if cond x y)}. Everything here is extended correctly but we end up
having boilerplate code, \textbf{semantically}.
\begin{figure}[!htb]\YZ{Make this part concise. (Just say this is a continuation of the earlier STLC example)}\EDJreply{Done}
\begin{lstlisting}[language=Coq,  escapeinside={@}{@}]
Family STLC.
  FInductive tm : Set := ... 
  FInductive value : tm -> Prop := ... 
  Closing Fact value_not_app : forall x y, ~ value (tm_app x y) 
      by { intros x y H; inversion H; eauto }.
  Fail Ltac inv := 
    match goal with 
    | [h : value (tm_app _ _) |- ] => destruct (value_not_app _ _ h)
    (* Fail: value, tm_app, value_not_app unfound *)
    end. 
  MetaData tactic1.
    Ltac inv := (* ... the same definition as above ... *)
  EndMetaData.
  (* ... STLC example continue ... *)
EndFamily.
\end{lstlisting}  
\caption{Example for Global Reasoning and MetaData, using in STLC example}\label{fig:plugin-example-global-reasoning-meta-data}
\end{figure}


Our proposal is to allow global reasoning by providing "Closing Fact" command. Ultimately, "Closing Fact" is asserting a constraint upon all the
possible extension of the surrounding family and claiming that a proof script
can solve the constraints.\YZ{This is a good one-liner that summarizes the intended usage scenarios of "Closing Fact". Should probably bring it out earlier.}\EDJreply{I put it here as you suggested but I think this one-liner at here will cause more confusion because it is too abstract.}
The assertion will only be verified when the whole family is closed and compiled into a module.

% We provide "Closing Fact" as a command to
% carry out this global reasoning, attached with a proof script and proof
% term. This "Closing Fact" will look like an assertion during the
% construction of the enclosing family. This assertion will only be
% verified when the whole family is closed and compiled into a module,
% with the help of the attached proof script and proof terms.

Here we show the example to prove "value_not_app" in
\cref{fig:plugin-example-global-reasoning-meta-data}, the script inside
curly brackets after "by" is the attached proof script that will be
executed upon "EndFamily", which triggers the compilation of the family
being defined.
Since we are dealing with a concrete (vanilla) inductive type during compilation,
we can use Coq's "inversion" tactic to complete this proof.
This "Closing Fact", as an assertion, will have no problem being
inherited, but the proof script will be executed every time a derived
family is compiled.

The downside is that "Closing Fact" cannot immediately check the correctness of the
attached proof term/proof script because this verification only happens when we
finished defining a family, and thus a bit harder to handle.\YZ{'harder' in what way? I suppose you mean the "Fail Ltac" in Figure 5?}\EDJreply{The proof script cannot be run immediately to reply the user whether the proof script is even correct. This is bad engineering to some extent. In those bad cases, because error only happens at the the very end ``EndFamily'' , the user will need to go back to the place of Closing Fact to adjust the proof script, or to adjust other parts. I am not sure if early check is possible to be done (engineering-wise) I think it is possible (imagine I just do an early compilation, i.e. only compile part of the family to the point closing fact is used) but it is a big engineering difficulty for me.}
We expect it to be used only sporadically for maintainability, and as an alternative to using "FRecursor". This is called global reasoning because this is a post-hoc reasoning when the family as a \textit{whole} is compiled into a module.



% However, to verify and prove the recursor and partial recursor and their
% computational rules (as in \ref{chg:definition-relevant-reasoning}), our plugin has to
% compile the extensible family into a non-extensible Coq Module and define
% the recursors by instantiating the content of Coq module with concrete
% inductive types. We provide "Closing Fact" as a command to carry out this global reasoning, 

% This style of ``Global Reasoning'' says that we can prove the
% corresponding theorem only when we know the ``full picture'', in particular,
% all the constructors of an inductive type. 
% We provide "Closing Fact" as
% a command to carry out this global reasoning

%\YZ{Are recursors and partial recursors automatically generated and proved by the plugin, or must they be asserted and proved by the programmer?}\EDJreply{(1) Closing Fact is not only used to generate recursor and partial recursor. I think the intro of this section is just giving people wrong impression. So I rewrite the whole section now. (2)  Recursors and Partial recursors are possible to be automatically generated but my plugin didn't implement it. Current stage is that user only need to assert them. Nobody has to prove it (plugin will prove it). Here when I say the user has to provide proof script, it means for arbitrary proposition if the user want to carry out global reasoning.}

% ---we can attach to "Closing
% Fact" either (proof) terms or Coq's proof script, then only when
% compilation to module happens, is the term/proof script
% type-checked to see if a "Closing Fact" statement can be proved. Note
% that, "Closing Fact" cannot immediately check the correctness of the
% term/proof script because this verification only happens when we
% finished defining a family, and thus a bit harder to handle.

% This "Closing Fact" also can ease us from the necessity to let plugin
% generate proof for recursors and partial recursors and their
% computational rules (as in \ref{chg:definition-relevant-reasoning}), and thus making
% plugin development easier.
%\YZ{This reads like a bad excuse: the programmer does not care about if the plugin development is easy. Question is if it makes the programmer's life easier.}\EDJreply{You are right. It does sound like a bad excuse. I rewrite the whole section now. Closing Fact is initially used when the user wants global reasoning instead of extensible proof by induction, for example, the inversion lemma. \\ It just happens that they can be used by me so that I can postpone generation of these rule plugin (which is hard for me to do). This paragraph is just me being honest that my plugin is not mature enough to generate everything.}
% For example, the computation rule for a
% concrete recursor like "B.neg" and partial recursors in
% \cref{fig:plugin-example2} can be directly asserted by using "Closing
% Fact" and their proofs verified later during compilation.
%\YZ{What is the alternative if not using "Closing Fact"?}\EDJreply{(1) For partial recursor and recursor, that should be generated by plugin (2) For general global reasoning, I don't know. There must be some other ways in the literature. }\YZ{Still not entirely clear to me what is gained and what is lost by using "Closing Fact".}\EDJreply{Please check.}
% This ``Global Reasoning'' will be again useful in later examples.

\textbf{Hack: ``Meta-data''.} Due to our implementation of the family,
the family data is invisible to Coq internal and thus causes some
inconvenience. For example, in
\cref{fig:plugin-example-global-reasoning-meta-data} the first attempt
of defining tactic "inv" fails. Because the earlier defining "tm",
"value", and "value_not_app" are currently just data structure in the
plugin and not visible for Coq internal (only visible after the family
is compiled into module). 

Thus to refer to them, we have to scope the defining tactic with
"MetaData" and our plugin will set up the appropriate environment. After
a "MetaData" block is closed, the plugin will aggregate the content into
the family being defined so that they can also be used when defining
the following fields of the family.\YZ{It reads like this MetaData wrapping could be automatically inserted, no?}\EDJreply{Not sure. This auto-insertion will practically look like hijack the original Coq command. I am not sure this kind of hijacking can happen.}
This can fulfill \ref{chg:software-engineering} and define new customized tactic.


% To fulfill \ref{chg:software-engineering}, we need somehow to aggregate tactic inside compiled module type, due to the implementation of our family---when defining every field of 

% For example, 

%   For example, currently it is not possible to define a
% vanilla inductive type dependent on our ``extensible'' inductive type
% due to the invisibility, unless we compile the whole family. Similarly,
% customized tactic expressions as required by \ref{chg:software-engineering} cannot
% use lemmas or theorems in the fields of the current defining family as
% well.

% To remedy this, we support a "MetaData" command. This command
% bundles any original Coq primitive (in the current family
% context) into the compiled module type, and makes them visible to the
% following defining field. Doing so, we can define customized tactic as
% in \ref{chg:software-engineering} that uses lemmas proved in the family.


% Following needs a rewrite

\textbf{Propositional Partial Recursor.} Notice that, for both "FRecursor" and "Closing Fact", they are not necessarily ``\textit{conservative extension}''---they will possibly disrupt arbitrary extension of inductive type. For example, for \cref{fig:STLC-example}, once we proved \mintinline{Coq}{var_not_value : ∀ i, ~ value (tm_var i)} in the "Family STLC" either using "FRecursor" or "Closing", then any children family of "STLC" cannot extend a new constructor \mintinline{Coq}{vvar: ∀ i, value (tm_var i)}. 

This raise an interesting question: what propositions are conservative extension? For example, apparently we know injectiveness of constructor, (i.e. \mintinline{Coq}{STLC.tt ≠ STLC.ff}) must be conservative because it holds for all extension of the inductive type "STLC.tm". But is there a \textbf{``best'' proposition} (i.e. the proposition that everything the proposition derives are exactly conservative extension)?

Since injectiveness of the constructors are derived by recursor in vanilla inductive type, an educated guess would be related to recursor. But we know the original recursor won't work because the mere existence of the original recursor will break extensibility. Thus we need to modify it.
The simplest idea is to allow partiality---i.e., returning
\mintinline{Coq}{option T} instead of the original \mintinline{Coq}{T}.

We call this \textit{propositional partial recursor}.\YZ{What is propositional about partial recursors? I suppose it has to do with the computational axioms?}\EDJreply{Yes. I want to emphasize the equality used by computational axiom is not judgemental equality. So Coq cannot automatically compute/reduce when a partial recursor applied to a term. This reduction can only be semi-automatically done by using [rewrite tactic and the computational axiom].}
For example, the propositional partial recursor for \mintinline{Coq}{B.b} is\YZ{Mention that partial recursors can be automatically generated}\EDJreply{Added below please check.}

\begin{minted}[escapeinside=@@]{Coq}
(* Inside Family B *)
FInductive b : Set := tt : b | ff : b.
b_prec : forall R, option R -> option R -> b -> option R.@\YZ{Not clear what it takes to define/prove partial recursors. The reader needs to be told if they require breaking abstraction like recursors do.}\EDJreply{What do you mean? recursor doesn't break abstraction but break extensibility. Below mentioned partial recursor doesn't break extensibility}@
\end{minted}
with appropriate computational axioms. This partial recursor differs from original recursor only by decorating an "option" with the return type thus possible to be automatically generated (and the case is similar for those computational axiom). The partiality doesn't break
extensibility (i.e. all future extensions of "b" can support this
"b_prec") because "b_prec" can just return "None" when bump into extended constructor in the future. 

The first thing to check is that, if partial recursor is theoretically enough for injectiveness of the constructor. The rough idea to achieve this
is to use "b_prec" to reflect our special inductive type into vanilla
inductive type, and use the original "injection" and "discriminate"
tactics. For example, we want to prove \mintinline{Coq}{B.tt ≠
B.ff}, we simply 
\begin{minted}{Coq}
Definition reflect : B.b → option bool 
                   := b_prec (fun _ => bool) (Some true) (Some false).
Definition tt_neq_ff : B.tt = B.ff → False.
(* Because B.tt = B.ff → reflect B.tt = reflect B.ff 
      → Some true = Some false    (by computational axiom)
      → False           (by discriminate of bool and injection of Some) *)
\end{minted}


Even though we cannot prove propositional partial recursor is \textit{the best},
the above "reflect" function implies that propositional partial
recursor is a good \textit{extensional characterization} of (non-indexed) extensible inductive type (with certain constraints)---because we can ``embed'' vanilla inductive types into
types supporting a partial recursor: "reflect" is actually a left
inverse of an injection "bool → self_B.b". A bit more formally, and
restricting our focus to non-indexed inductive types:

\begin{theorem}\label{thm:prec-complete} Given a list of $n$ pairs of types $\{ x : "A"_i \vdash "B"_i(x) \}_{i}$ s.t.


  \begin{itemize}
    \item \textlabel{(Detectable Partiality)}{prop:detectable-partiality} for each pair $x : A_i \vdash B_i(x)$,
    \begin{minted}{Coq}
      Axiom detectable:
      forall {T} {a} (f: Bᵢ a -> option T),
        {forall x, f x <> None} + {exists x, f x = None}.
    \end{minted} 
    \item Define $"C"$ as the inductive type using this list, i.e.,
    \begin{minted}{Coq}
Inductive C : Set := ... | cᵢ : forall (x : Aᵢ), (Bᵢ x -> C) -> C | ...
    \end{minted}
    \item Assume an arbitrary type \mintinline{Coq}{D : Set} with
    \begin{itemize}
      \item $n$ \textbf{functions} \mintinline{Coq}{dᵢ : forall (x : Aᵢ), (Bᵢ x -> D) -> D}  
      \item a partial recursor
      \begin{minted}[escapeinside=@@]{Coq}
prec : forall (R : Set), ..,  @\YZ{Can R be indexed?}\EDJreply{This part actually currently incorrect and needs an extra constraint. Let me fix other parts first}@
  (rᵢ : (forall (x : Aᵢ), (Bᵢ x -> option R) -> option R)), .., 
      D -> option R
      \end{minted}
      \item and $n$ (propositional) computational axioms: for all $i$, 
      \begin{minted}{Coq}
prec {R} r₁ r₂ .. rₙ (dᵢ aᵢ bᵢ) 
    = rᵢ aᵢ (fun x => prec {R} r₁ r₂ .. rₙ (bᵢ x))
      \end{minted}
    % where \mintinline{Coq}{(lift rᵢ) : (forall (x : Aᵢ), (Bᵢ x -> option R) -> option R)} is defined as expected
    \end{itemize}
  \end{itemize}
  Then there exists an \textbf{embedding} from "C" to "D".
  More concretely, we can have \mintinline{Coq}{inj : C -> D} and 
  \mintinline{Coq}{linv : D -> option C} defined using the eliminator of
  "C" and "prec" of "D" (both acting like identity) such that
  \begin{minted}[escapeinside=@@]{Coq}
    forall c : C, linv (inj c) = some c@\YZ{Does 'linv' correpsond to 'reflect' above? If so, then the reader should be explicitly reminded of this fact rather than having to guess it.}\EDJreply{Added below. I mentioned left inverse 'linv' is the generalization}@
  \end{minted}
\end{theorem}
The reason we have this weird looking \ref{prop:detectable-partiality} is because the construction of "linv"---at one point, using "prec" to construct "linv", we need to prove \mintinline{Coq}{∀ a, (Bᵢ a → option C) → option C}, generally not provable, only if we have \mintinline{Coq}{option (Bᵢ a → C)} as an argument instead. This \ref{prop:detectable-partiality} is exactly transforming former to the later: recall that, according to the semantic of inductive type, \mintinline{Coq}{(Bᵢ a → option C)} is actually the result of using "linv" on the substructure of "D". This function points out each of the translation result from "D" to "C" and some of them are "None" because of failing. For us, we only care about if \textbf{any} of the substructure of "D" is failed to translate---if any one substructure fails, then the whole transltion fails and thus we should have "None" as return. 

\ref{prop:detectable-partiality} is derivable for all the finitary branching inductive type\footnote{By simply enumerating through the finite domain "Bᵢ a"}---that includes all of the examples shown in this paper. \ref{prop:detectable-partiality} is not supported when using function (infinitary branching) in the constructors, for example, the case of using \textit{higher order abstract syntax} to represent functions in "tm". In those cases, we still have the fact that partial recursor is a conservative extension, but we cannot show that partial recursor is the extensional characterization any more。


We emphasize that in \cref{thm:prec-complete}, each function $"d"_i$ can
actually be considered as a constructor, because they can be reflected
to real constructors of "C" using the left inverse "linv" (directly generalization of "reflect : self_B.b → option bool" of the above). Thus, \cref{thm:prec-complete}
implies that (1) every future extension of the inductive type can
support this partial recursion (trivially); (2) every type supporting
this partial recursor with its computational axioms at least supports
these constructors because of the embedding. In other words, \textit{a
type (at least) supports these constructors if and only if this type
supports the corresponding partial recursor (with the computational
axioms)}.  Thus, we can argue that the partial recursor gives a sound and
complete extensional characterization of all the extension of a given (non-indexed)
inductive type.\YZ{What about indexed inductive types?}\EDJreply{Done. I also have a formalization of this proof now, for indexed type and dependent eliminator. Though the formalization is about single constructor.}

We can support partial dependent eliminator as well, but partial dependent eliminator can deduce "prec" and our "prec" is enough to contruct this left inverse for (non-indexed) inductive type. 
\begin{minted}{Coq}
  pdelim : ∀ (P : D -> Set), .., 
  (rᵢ : (∀ (x : Aᵢ) (w : Bᵢ x -> D), (∀ (b : Bᵢ x), option (P (w b))) 
    -> option (P (dᵢ x w)))),  .., ∀ (d : D) -> option (P d)
\end{minted}
To generalize to indexed inductive type, we need to base on indexed W type~\cite{martin1982constructive, morris2009indexed,jashug2017} and dependent eliminator is unavoidable. Please refer to the supplementary material and appendix for a formalization of the left inverse in the context of indexed inductive type.   
