In this section, we describe how we can implement the proposed Vernacular commands.

After considering the pros and cons, we decide to implement a Coq Plugin in which we can add new Vernacular commands and translate each new command into a bunch of Coq commands (the surface Vernacular command) on the fly, instead of modifying the code-base of Coq. 

Despite possible difficulties for future maintenance, this approach has
various advantages: 1. it is the easiest and the most accessible way to
prototype as it relieves us the necessity of familarity of Coq base,
especially for the implementation of the module and functor; 2. we have
a clear definition of trusted-base---the whole Coq; 3. it is easy to
debug---we just need to check the translated commands; 4. it can be
well-incorporated with the existent tools like VSCoq; 5. it is more
accessible for the interested audience who can then easily adapt our
plugin and give a try---otherwise they have to download and re-build the
whole customized Coq; 6. it is more stable because the surface syntax of
Coq should be stable across different versions; 7. still, this plugin
can capture the key ingredients of implementing family polymorphism
inside Coq and act as a reference for guiding an appropriate
implementation of Family Polymorphism inside all sorts of proof
assistants.\YZ{Does the Coq implementation perform type checking to
prevent illegal uses fam poly?}\EDJreply{Yes. Because I define feature of fampoly as a direct translation into Coq feature.  The fampoly is like a shorthand into multiple Coq commands. \\
Do you find translation from my current metatheory into MLTT (without linkage) helpful? \\
Actually I am also not sure what this question is aiming towards. \\
Are you complaining there is no formal specification of my fampoly feature in paper and thus there is no proof my Coq surface syntax is related to metatheory? If so, I thought our Coq plugin is only advertising how powerful Fampoly is to solve expression problem in mechanized proving. I can decouple the relationship between our plugin and our metatheory if you find the gap is really there... And I can only claim metatheory is about a partial result on incorporating fampoly with dependent type, Coq plugin is using two example to illustrate how mechanized proving can get benefit and our Coq plugin is only inspired by our metatheory (and not claim any relationship). Doing so would require rearrange the metatheory section before this section. \\
But I don't think the gap is there at all because if you want all possible gaps to disappear, then the action of using debruijn is wrong because we need to prove the one using debruijn and the surface syntax that is not using debruijn are ``equivalent''. What's more, module is not sigma type because Module is not a term in Coq and thus there is no formalism of Module at all. Let alone I don't see the plausibility of mechanizing dependent type without debruijn. \\ 
Please comment back so that I know what corresponding modification is needed on the paper. 
}\YZreply{My original question was more directed towards the fact
that currently type checking is deferred to the Coq base. Generally,
when one uses a statically typed language as a compilation target, they
also want to have type checking at the source level, (1) because there
could be type errors at the source level that could not otherwise be
caught at the target level and (2) because it allows better error messages.
So it needs to be addressed why deferring type checking to Coq is OK.}\EDJreply{Good point. I think (1) is largely mediated by the fact the semantic of family is very close to that of the module. And the supporting feature is simple enough that there won't appear some problems like type error at source-level but not target level(2) is happening for sure but some basic error message is almost "transparent" i.e. the error-messages from Coq can be directly interpreted for the user. But my justification is solely empirical and as you know the empirical study for this paper is not really strong enough to support anything.}


\textbf{Family compiled into module.} This is the main idea of compiling
family components into Coq's primitives: we compile families into Coq
modules, family types into module types, and the context of a given term
into parameters of the module. Unlike module, we need to faithfully
reflect the \textit{late binding} nature of families: for each defining
field $ .. \cL\sigma \vdash t : T $, we need to compile $t$ using
``universal-quantifier-wrapped term'' : $.. \vdash \lambda t : \forall
\cL \sigma. T$. However, instead of using Coq's universal quantifier, we
choose module and module parameters to achieve this wrapping---each
family type in the context of the judgement will be one module parameter
with the compiled module type, and thus each field of the family will
compile into a functor parametrized by its context. Doing so we can also
get rapid feedback from type checking when the users are defining each
field interactively with Coq.
% Insert one pseudo-code example for explanation of the mechanism
\begin{figure}[!htb]
  \begin{minipage}[t]{0.25\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Family A.
Field a : nat 
  := 1.
Field b : a = a
  := eq_refl.
Final Field a' : nat 
  := 1. 
Field b' : a' = 1
  := eq_refl.
EndFamily.
\end{minted}
  \end{minipage}%\YZ{Can the self's be omitted?}\EDJreply{Yes. But in our current plugin implementation it is not omitted. I think altering example is fine. If you think some small distance between example and the current implementation is fine, please comment back and I will remove all the self_}\YZreply{If omitting the self's poses no technical challenges, then I'd say it's fine to also omit them in this figure.}\EDJreply{Omitting self_ is easy and not much engineering effort is required. But omitting self_ will lead to `A.a' instead of `a' actually. So if we really want `a' as you last time mentioned, then a resolution is required and more engineering effort is required. But I don't see any technical difficulties. I have removed all the self, please check.}
  \begin{minipage}[t]{0.4\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Module a_4 (self_A: EmptySig).
Definition a : nat := 1. End a_4.
Module Type a_5 (self_A: EmptySig).
Parameter (a : nat). End a_5.
Module Type a_6 := a_5 EmptyMod.
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.3\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Module b_7 (self_A: a_6).
Definition b 
  : self_A.a = self_A.a 
  := eq_refl. End b_7.
  
Module A. (* Final Aggregation *)
Include a_4. Include b_7. End A.
\end{minted}
  \end{minipage}
  \caption{Example Code and Plugin Translation}\label{fig:plugin-example1}
\end{figure}


% Concrete details of compilation of a family term data structure
Taking \cref{fig:plugin-example1} as an example: when the user
interactively inputs the line "Field a : nat := ..", our plugin will
translate this statement into the "Module a_4", "Module Type a_5, a_6"
three components.
{The "EmptySig" is just empty module type.} Then,
these modules and module types will be generated and type-checked by Coq
immediately. The compiled "Module a_4" is then part of the context of
"Field b" (as the module type of "self_A") for "b" to refer to. The
internal representation of family "A" is the list of these
compiled modules and module types. We can achieve incremental
checking and overriding as in \ref{langdesign-req0}---for example, if we
want to override "Field a", we simply replace that compiled module with
the new module inside the list. This compiled module type serves as an
abstraction that enables overriding.

Now that we know a family declaration is compiled to a list of Coq
modules and module types, we may want to aggregate them into one complete compiled
module.\YZ{The reader wonders why this aggregation is needed. Seems like the place to talk about how the programmer can use A outside Family A.}
We achieve that by repeatedly using Coq's "Include" command as
the example illustrates. Note that, in our example, we include two
functors without arguments---this is due to a peculiarity of Coq's
"Include": non-instantiated parameters will be automatically
instantiated by the appropriate fields in the surrounding defining
module.
For example, "b_7" requires a module of type "a_6". Inside module "A",
when "Include a_4" is done, we will have a field \mintinline{Coq}{a : nat}
inside the current surrounding "A". Then when we
\mintinline{Coq}{Include b_7} without specifying the module parameter,
Coq will try to find fields in the surrounding module (i.e., module
"A") to instantiate \mintinline{Coq}{self_A: a_6}. This is satisfied by
the \mintinline{Coq}{a : nat} that is included earlier.
The resulting compiled module is just like mundane Coq's module and thus maintains all the computational mechanism from Coq, fulfilling \ref{langdesign-req0b}. 



% explaining inheritance
Besides standalone family, we also need to implement family inheritance.
To simplify the implementation, we can consider all families as
inheritance and the standalone families are extending the empty family.
Thus we need to deal with only inheritance during interactive proving. 

An inheritance data\YZ{what is 'inheritance data'?}\EDJreply{It is just inheritance judgement, but before meta-theory is introduced, I can only say some "first-order data that represent the information of inheritance". I emphasize first order to distinguish from functor in ML community.} 
will be annotated with the type for the input family
and output family. There are three kinds of inheritance---extend,
override, and inherit. Extending corresponds to adding new fields,
overriding corresponds to modifying existent fields, and inheriting
corresponds to directly taking fields from the parent.
Thus, it is possible to consider inheritance as solely a data rather
than a functor, and this actually provides us the possibility to
\text{mix-in} inheritance data. 




\textbf{Reasoning Requires Non-Overridable.} This compilation strategy
can allow fields to be type-dependent on former fields thus fulfilling
\ref{langdesign-req1}. However, there are cases where we need to expose
the concrete definition of a given field (especially when we are proving
properties about it).

For example, we may
define $"add" : \mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}$ as one field
and intend to prove its commutativity in a following field $"comm"$.
But to prove so, we need to know more than just a type interface of
"add" but also its \textbf{concrete fixpoint definition}. Otherwise, in the
future, once "add" is overridden into a subtraction function then
"comm" will have problem to be inherited.\YZ{The sentence reads as if you want to enable overriding "add", whereas what you really want is to expose the definition equality about "add".}
A more concrete example is in \cref{fig:plugin-example1}, consider the
case we have "Field b : a = 1 := .." instead. Then our
compilation and Coq's type checking will both fail: in the context of
"b" (module type "a_6") we only know "a" is of type "nat" but nothing
more (and this is necessary so that "a" can be overridden in the
future).\YZ{Not clear if you want to be able to override a or want to be able to have 'Field b : a = 1'.}

To fix that, we need more information on "a" than its type---we
need to expose the concrete definition "a = 1" to the context of "b".
%\YZ{I had a hard time working through these two paras. I guess they are
%saying that there is a need to expose definitional equalities, and
%therefore we need non-overridables. This causal flow should be made
%more explicit.}\EDJreply{Good suggestion. I try to add this casual flow into the first line of the paragraph. Please check and resolve if find satisfied.}

In our Coq plugin, we can achieve such exposure of definitional equality by
exposing the whole definition directly into the compiled module type. Doing so we also prohibit overriding because
subtraction doesn't have the same definition as $add$. We require the
users to decorate field as `Final' so that the plugin will proceed with
this special treatment.\YZ{This para is confusing: which kind of equality is used, propositional or judgmental? Where does 'Final' show up in the example?}\EDJreply{I rephrase it and remove the part on taking about meta-theory. Now everything is about judgemental so I don't have to emphasize judgemental. I wanted to make the example small but I guess I can add one `Final' statement into our example. Don't resolve it until I add it into Figure 2.}

\textbf{Special Fields: Overridable and Sealed Family as Interface.} 
Non-overridable field is still not expressive enough to achieve the full extent of the dependent type programming. There are cases reasoning and overriding are both required, especially when we need to use Coq to do computation. For example, we may want a field to be an arbitrary monotonic function. Again, we cannot split into two fields \mintinline{Coq}{(f : nat → nat; p : monotonic f)} because to provide "p" we need to have concrete definition of "f" in the family type, which makes "f" non-overridable at all. One option is to use sigma type \mintinline{Coq}{{f | monotonic f}} but that is cumbersome when we have a bundle of stuff with multiple refinements. 

To resolve this, we provide family sealing mechanism---basically we allow the users to specify the family/compiled module type, and thus we can have a \textit{locally transparent}, \textit{non-overridable} field located in a \textit{overridable} family. Using the above example, we simply make \mintinline{Coq}{(f : nat → nat, p : monotonic f)} together inside an \textit{overridable} family, but "f" to be non-overridable and transparent on its definition, and thus we can prove "p". Once we want to swap the implementation, we just override the whole ``sealed'' family.

This ``sealed'' family actually simulate interface to a certain level---we can assign each field of the sealed family with \mintinline{Coq}{Axiom non_implement : forall {T : Type}, T.}, and later instantiate them with concrete implementation by overriding this family.
% Basically, {a : int -> int; property : a is monotonic}, in this case
%   we may want to override "a" using different computation, but we still wnat
%   this refinement/property



\textbf{Special Fields: ``Extensible'' Inductive Type and Defining Recursor.}
We don't actually support extensible inductive type from \ref{langdesign-req2} in Coq (because that require non-trivial research effort on theory side---i.e. {What is the semantic of extensible inductive type?}---and engineering), but we simulate extensible inductive type using overriding---when extending an inductive type $A$ with new constructors $c$, our plugin will generate a new inductive definition $A'$ with this new $c$ on the fly and feed to Coq.  But still, we must be careful on the exposing data in the family type (the compiled module type) for the following field.  

% Insert one pseudo-code example for explanation of the mechanism
% Use the natural number example
\begin{figure}[!htb]
  \begin{minipage}[t]{0.3\linewidth}
\begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}
Family B.
  FInductive b : Set 
    := tt : b | ff : b.
  Family neg_handler. 
    Field tt : self_B.b 
      := self_B.ff.
    Field ff : self_B.b 
      := self_B.tt.
  EndFamily.
FRecursor neg 
  about self_B.b 
  motive (fun _ => self_B.b)
  using self_B.neg_handler
  by _rec.
EndFamily.

Family B2 extends B.
  Extend FInductive b : Set 
    := uu : b.
  Extend Family neg_handler.
    Field uu : self_B2.b 
      := self_B2.uu.
  EndFamily. 
EndFamily.
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.65\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
  (* Abstraction for Inductive Type *)
Module Type b_3 (self_B: EmptySig_4).
Parameter (b : Set). Parameter (tt ff : b). End b_3.      
Module Type b_6 := b_3 EmptyMod.
  (* Recursor to Set for b *)
Module b_rec_12 (self_B: b_6).
Definition __recursor_type_b_rec :=
  forall P : self_B.b -> Set,
  P self_B.tt -> P self_B.ff 
  -> forall __i : self_B.b, P __i. End b_rec_12. 
  (* Field B.neg_handler.ff *)
Module ff_24 (self_B: b_6) 
             (self__neg_handler: tt_23 self_B).
Definition ff : self_B.b := self_B.tt. End ff_24.
  (* Intermediate Module solely for type checking *)
Module v_33_34 (self_B: neg_handler_26).
Include b_rec_12 self_B.
Parameter (recursor_for_type_checking : __recursor_type_b_rec).
Definition term_for_type_checking :=
  recursor_for_type_checking (fun _ : self_B.b => self_B.b)
    self_B.neg_handler.tt
    self_B.neg_handler.ff.  
End v_33_34.
\end{minted}
  \end{minipage}
\caption{Example Code for Inductive Type}\label{fig:plugin-example2}
\end{figure}

Let's look at \cref{fig:plugin-example2}, the example of boolean and negation. When we define inductive type "b", the following "Field neg_handler.ff" can only know "b" is a type (of "Set") and there are at least two constructors for it, just like what we declare in ``the abstracted interface'' the compiled module type "b_3". We cannot export the eliminator of "b" inside "b_3" because doing so "neg_handler.ff" (and "ff_24") will not be able to be inherited to the context where "b" is extended with a third constructor, since the existence of recursor alone will assert that there are only two constructors in "b", not ``extensible'' at all!   

But we do have to provide a way to construct an (extensible) recursor (as in \ref{langdesign-req3}), and execute type checking (and exhaustiveness checking). Thus we need to extract a elimination principle for future usage. Here we show one exemplar extraction of the recursor in \mintinline{Coq}{Set} as module "b_rec_12".

To construct a recursor as in \ref{langdesign-req3}, we make for each constructor a handler and aggregate them inside a family. The whole family "neg_handler" can be considered as a large matching case. Doing so, family inheritance can function as matching-case reuse. Then we use "FRecursor" to specify the motive and inductive type. Here "FRecursor" will feed Coq
a module "v_33_34" for doing type-checking---what it does is basically assert the existence of the recursor and apply to see if handlers can pass the type checking by Coq. 

Since the recursor is constructed knowing a concrete inductive type, thus not inheritable, for all the children, we have to reconstruct and override with a new recursor (acting like an extra exhaustiveness checking). This is affordable since each recursor handler doesn't need to be rechecked---look at "B2.neg_handler", there is only one new handler for "uu" and the handlers from the parent "B.neg_handler.tt,B.neg_handler.ff" are already type-checked and inherited(thanks to the fact that they only rely on ``the abstracted interface'' module "b_3"). Of course, our plugin will ``inherits'' the recursor "neg" but what the plugin does is doing exhaustiveness checking, again.

% Explain why the module type need extra care

% explain how recursor is constructed
% explain we have the incremental-checking for any recursor 

% explain ftheorem wrapping this complicated recursor
We also provide a command "FTheorem" when the users want to use tactic programming instead. This tool can avoid most boiler-plate code (e.g. specify the handler family) when writing a recursor like above, invoke proof interaction mode, allow tactic usage, and is also open to extension like "FRecursor".

To summarize, the key insight here is that, to make each recursor handler inheritable, we need to seal an abstraction around the inductive type (e.g. module "b_3"); but to construct a recursor (and carry out the exhaustiveness checking), we need to break this abstraction and see the concrete definition of the inductive type (e.g. module "b_rec_12"). Our meta-theory need to handler these two seemingly contradicting ideas simultaneously. 


\textbf{Propositional Partial Recursor.}
Apparently, the exposed module "b_3" in \cref{fig:plugin-example2} is not expressive enough to really fulfill \ref{langdesign-req2}. For example, we cannot prove the constructors are injective, i.e. \mintinline{Coq}{self_B.tt ≠ self_B.ff}. In the original setting, to prove injectiveness of constructor of (vanilla) inductive type, we only require a recursor and its computational rules. However, as we pointed out earlier, the recursor of an inductive type cannot be exposed into the context for the sake of extensibility. Thus we need to alter the formulation of the recursor i.e., we need to have a better characterization of ``extensible inductive type'' exported in the compiled module type as a part of the interface for the following fields to use.


The simplest idea is to allow partiality---i.e. returning \mintinline{Coq}{option T} instead of the original \mintinline{Coq}{T}. We call this \textit{propositional partial recursor}. For example, the propositional partial recursor for \mintinline{Coq}{B.b} is 
\begin{minted}{Coq}
b_prec : forall P : b -> Set, P tt -> P ff 
    -> forall x : b, option (P x). 
\end{minted}
with appropriate computational axioms. The partiality doesn't break extensibility (i.e. all the future extension of "b" can support this "b_prec"). 

What's more, partial recursor is theoretically enough for the "injection" and "discriminate" tactics. The rough idea to achieve this is to use "b_prec" to reflect our special inductive type into vanilla inductive type, and use the orignal "injection" and "discrimination" respectively. For example, we want to prove \mintinline{Coq}{self_B.tt ≠ self_B.ff}, we simply 
\begin{minted}{Coq}
Definition reflect : self_B.b → option bool 
                   := b_prec (fun _ => bool) true false.
Definition tt_neq_ff : self_B.tt = self_B.ff → False.
(* Because self_B.tt = self_B.ff → reflect self_B.tt = reflect self_B.ff 
                → true = false    (by computational axiom)
                → False           (by discriminate of bool) *)
\end{minted}



In fact, the above "reflect" function implies that propositional partial recursor is good enough to some extent, at least for non-indexed inductive type, because we can ``embed'' vanilla inductive type into types supporting partial recursor. Because "reflect" is actually a left inverse of an injection "bool → self_B.b". A bit more formally, and restrict our focus to non-indexed inductive types,

\begin{theorem}\label{thm:prec-complete} Given a list of $n$ pairs of types $\{ x : "A"_i \vdash "B"_i(x) \}_{i}$
  \begin{itemize}
    \item Define $"C"$ as the inductive type using this list, i.e. 
    \begin{minted}{Coq}
Inductive C : Set := ... | cᵢ : forall (x : Aᵢ), (Bᵢ x -> C) -> C | ...
    \end{minted}
    \item Assume an arbitrary type \mintinline{Coq}{D : Set} that has ...
    \begin{itemize}
      \item following $n$ \textbf{functions} \mintinline{Coq}{dᵢ : forall (x : Aᵢ), (Bᵢ x -> D) -> D}  
      \item a partial recursor 
      \begin{minted}{Coq}
prec : forall (R : Set), ..,  
  (rᵢ : (forall (x : Aᵢ), (Bᵢ x -> R) -> R)), .., D -> R
      \end{minted}
      \item all the following $n$ (propositional) computational axioms: for all $i$, 
      \begin{minted}{Coq}
prec {R} r₁ r₂ .. rₙ (dᵢ aᵢ bᵢ) 
    = rᵢ aᵢ (fun x => prec {R} r₁ r₂ .. rₙ (bᵢ x))
      \end{minted}
    \end{itemize}
  \end{itemize}
  We will have an \textbf{embedding} from "C" to "D", more concretely, we can have \mintinline{Coq}{inj : C -> D} and 

  \mintinline{Coq}{linv : D -> option C} defined using eliminator and "prec", (both act similar to identity) such that
  \begin{minted}{Coq}
    forall c : C, linv (inj c) = some c
  \end{minted}
\end{theorem}

We emphasize that in \cref{thm:prec-complete}, each function $"d"_i$ can actually be considered as a constructor, because they can be reflected to real constructors of "C" using "linv". Thus, \cref{thm:prec-complete} implies that (1) every future extension of the inductive type can support this partial recursion (trivially); (2) every type support this partial recursor with its computational axiom at least support these constructors because of the embedding. In other words, \textit{a type (at least) supports these constructors if and only if this type supports the corresponding partial recursor (with the computational axiom)}.  Thus we can argue that the partial recursor gives a sound and complete characterization of all the extension of a given (non-indexed) inductive type.

% Mention still needing total recursor, for exhaustiveness checking

\textbf{Hack: Global Reasoning.}
% explain the places using ``Closing Fact''
% 1. No need to export partial recursor
% 2. Computational rule for the total recursor
However, to verify and prove the recursor and partial recursor and their computational rules (as in \ref{langdesign-req4}), our plugin has to compile the extensible family into a non-extensible Coq Module and prove the recursors by instantiating the content of Coq module with concrete inductive type.  

This style of ``Global Reasoning'' is that we can only prove the corresponding theorem when we know the ``full pictures'', especially the inductive type. We provide "Closing Fact" as a command to carry out this global reasoning---we can attach "Closing Fact" with either (proof) terms or Coq's proof script, then only when compilation to module happens, the term/proof script will put into type-check to see if a "Closing Fact" statement can be proved. Note that, "Closing Fact" cannot immediately check the correctness of the term/proof script because this verification only happens when we finished defining a family, and thus a bit harder to handle.

This "Closing Fact" can ease us from the necessity to let plugin generate proof for recursors and partial recursors and their computational rules (as in \ref{langdesign-req4}), and thus making plugin development easier. For example, the computation rule for a concrete recursor like "B.neg" and partial recursors in \cref{fig:plugin-example2} can be directly asserted by using "Closing Fact" and verified later during compilation. This ``Global Reasoning'' will be again useful in the later examples.

\textbf{Hack: ``Meta-data''.} Due to our implementation of the family, the family data is invisible for Coq internal and thus cause some inconvenience.  For example, currently it is not possible to define a vanilla inductive type dependent on our ``extensible'' inductive type due to the invisibility, unless we compile the whole family. Similarly, customized tactic expression requested by \ref{langdesign-req5} cannot use lemmas or theorems in the fields of the current defining family as well.

To remedy this, we facilitate a "MetaData" command. This command will allow to bundle any original Coq primitive (in the current family context) into the compiled module type, and thus visible to the following defining field. Doing so, we can define customized tactic as in \ref{langdesign-req5} that uses lemmas proved in the family. 