In this section, we describe how we can implement the proposed Vernacular commands.

After considering the pros and cons, we decide to implement a Coq Plugin in which we can add new Vernacular commands and translate each new command into a bunch of Coq commands (the surface Vernacular command) on the fly, instead of modifying the code-base of Coq. 

Despite possible difficulties for future maintenance, this approach has
various advantages: 1. it is the easiest and the most accessible way to
prototype as it relieves us the necessity of familarity of Coq base,
especially for the implementation of the module and functor; 2. we have
a clear definition of trusted-base---the whole Coq; 3. it is easy to
debug---we just need to check the translated commands; 4. it can be
well-incorporated with the existent tools like VSCoq; 5. it is more
accessible for the interested audience who can then easily adapt our
plugin and give a try---otherwise they have to download and re-build the
whole customized Coq; 6. it is more stable because the surface syntax of
Coq should be stable across different versions; 7. still, this plugin
can capture the key ingredients of implementing family polymorphism
inside Coq and act as a reference for guiding an appropriate
implementation of Family Polymorphism inside all sorts of proof
assistants.\YZ{Does the Coq implementation perform type checking to
prevent illegal uses fam poly?}\EDJreply{Yes. Because I define feature of fampoly as a direct translation into Coq feature.  The fampoly is like a shorthand into multiple Coq commands. \\
Do you find translation from my current metatheory into MLTT (without linkage) helpful? \\
Actually I am also not sure what this question is aiming towards. \\
Are you complaining there is no formal specification of my fampoly feature in paper and thus there is no proof my Coq surface syntax is related to metatheory? If so, I thought our Coq plugin is only advertising how powerful Fampoly is to solve expression problem in mechanized proving. I can decouple the relationship between our plugin and our metatheory if you find the gap is really there... And I can only claim metatheory is about a partial result on incorporating fampoly with dependent type, Coq plugin is using two example to illustrate how mechanized proving can get benefit and our Coq plugin is only inspired by our metatheory (and not claim any relationship). Doing so would require rearrange the metatheory section before this section. \\
But I don't think the gap is there at all because if you want all possible gaps to disappear, then the action of using debruijn is wrong because we need to prove the one using debruijn and the surface syntax that is not using debruijn are ``equivalent''. What's more, module is not sigma type because Module is not a term in Coq and thus there is no formalism of Module at all. Let alone I don't see the plausibility of mechanizing dependent type without debruijn. \\ 
Please comment back so that I know what corresponding modification is needed on the paper. 
}\YZreply{My original question was more directed towards the fact
that currently type checking is deferred to the Coq base. Generally,
when one uses a statically typed language as a compilation target, they
also want to have type checking at the source level, (1) because there
could be type errors at the source level that could not otherwise be
caught at the target level and (2) because it allows better error messages.
So it needs to be addressed why deferring type checking to Coq is OK.}\EDJreply{Good point. I think (1) is largely mediated by the fact the semantic of family is very close to that of the module. And the supporting feature is simple enough that there won't appear some problems like type error at source-level but not target level(2) is happening for sure but some basic error message is almost "transparent" i.e. the error-messages from Coq can be directly interpreted for the user. But my justification is solely empirical and as you know the empirical study for this paper is not really strong enough to support anything.}


\textbf{Family compiled into module.} This is the main idea of compiling
family components into Coq's primitives: we compile families into Coq
modules, family types into module types, and the context of a given term
into parameters of the module. Unlike module, we need to faithfully
reflect the \textit{late binding} nature of families: for each defining
field $ .. \cL\sigma \vdash t : T $, we need to compile $t$ using
``universal-quantifier-wrapped term'' : $.. \vdash \lambda t : \forall
\cL \sigma. T$. However, instead of using Coq's universal quantifier, we
choose module and module parameters to achieve this wrapping---each
family type in the context of the judgement will be one module parameter
with the compiled module type, and thus each field of the family will
compile into a functor parametrized by its context. Doing so we can also
get rapid feedback from type checking when the users are defining each
field interactively with Coq.
% Insert one pseudo-code example for explanation of the mechanism
\begin{figure}[!htb]
  \begin{minipage}[t]{0.25\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Family A.
Field a : nat 
  := 1.
Field b : a = a
  := eq_refl.
Final Field a' : nat 
  := 1. 
EndFamily.
\end{minted}
  \end{minipage}%\YZ{Can the self's be omitted?}\EDJreply{Yes. But in our current plugin implementation it is not omitted. I think altering example is fine. If you think some small distance between example and the current implementation is fine, please comment back and I will remove all the self_}\YZreply{If omitting the self's poses no technical challenges, then I'd say it's fine to also omit them in this figure.}\EDJreply{Omitting self_ is easy and not much engineering effort is required. But omitting self_ will lead to `A.a' instead of `a' actually. So if we really want `a' as you last time mentioned, then a resolution is required and more engineering effort is required. But I don't see any technical difficulties. I have removed all the self, please check.}
  \begin{minipage}[t]{0.4\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Module a_4 (self_A: EmptySig).
Definition a : nat := 1. End a_4.
Module Type a_5 (self_A: EmptySig).
Parameter (a : nat). End a_5.
Module Type a_6 := a_5 EmptyMod.
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.3\linewidth}
\begin{minted}[fontsize=\footnotesize]{Coq}
Module b_7 (self_A: a_6).
Definition b 
  : self_A.a = self_A.a 
  := eq_refl. End b_7.
  
Module A. (* Final Aggregation *)
Include a_4. Include b_7. End A.
\end{minted}
  \end{minipage}
  \caption{Example Code and Plugin Translation}\label{fig:plugin-example1}
\end{figure}


% Concrete details of compilation of a family term data structure
Taking \cref{fig:plugin-example1} as an example: when the user
interactively inputs the line "Field a : nat := ..", our plugin will
translate this statement into the "Module a_4", "Module Type a_5, a_6"
three components.
{The "EmptySig" is just an empty module type.} Then,
these modules and module types will be generated and type-checked by Coq
immediately. The compiled "Module a_4" is then part of the context of
"Field b" (as the module type of "self_A") for "b" to refer to. The
internal representation of family "A" is the list of these
compiled modules and module types. We can achieve incremental
checking and overriding as in \ref{langdesign-req0}---for example, if we
want to override "Field a", we simply replace that compiled module with
the new module inside the list. This compiled module type serves as an
abstraction that enables overriding. 

Once the user closes a family with "EndFamily", they can access its fields by using module syntax. For example, they can access "A.a" to get "1" after "Family A" is defined. This is achieved by a complete compilation from a family to a module, via aggregating the list of the modules in the internal representation: the plugin will repeatedly using Coq's "Include" command as the "Module A" in \cref{fig:plugin-example1} illustrates. Now, the user can use "Module A" anywhere as they are using "Family A".
\YZ{The reader wonders why this aggregation is needed. 
Seems like the place to talk about how the programmer can use A outside Family A.}\EDJreply{Please check.}

Note that, in our example, we include two
functors without arguments---this is due to a peculiarity of Coq's
"Include": uninstantiated parameters will be automatically
instantiated by the appropriate fields in the surrounding defining
module.
For example, "b_7" requires a module of type "a_6". Inside module "A",
when "Include a_4" is done, we will have a field \mintinline{Coq}{a : nat}
inside the current surrounding "A". Then when we
\mintinline{Coq}{Include b_7} without specifying the module parameter,
Coq will try to find fields in the surrounding module (i.e., module
"A") to instantiate \mintinline{Coq}{self_A: a_6}. This is satisfied by
the \mintinline{Coq}{a : nat} that is included earlier.
The resulting compiled module is just like mundane Coq's module and 
thus maintains all the computational mechanism from Coq, fulfilling \ref{langdesign-req0b}. 



\begin{figure}[!htb]
  \begin{minipage}[t]{0.45\linewidth}
\begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}
Family I.
 Field a : nat := 1.
 Field b : a = a := eq_refl.
 Fail Field c : a = 1 := eq_refl. (*Fail 1*)

 Final Field a' : nat := 1.
 Field c : a' = 1 := eq_refl.
 Field bop : nat -> nat -> nat := (+).
 Fail Field comm_add : ...

 Family MonotonicF.
  Final Field f : nat -> nat := non_impl.
  Field p : monotonic f := non_impl.
 SealFamily. 
EndFamily.
\end{minted}
  \end{minipage}
\begin{minipage}[t]{0.45\linewidth}
\begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}
Family I2 extends I.
 Override Field a : nat := 1. (* Override *)
 Inherit b.                   (* Inherit  *)

 Field d : nat := a.          (* Extend   *)
 Fail Override Field a' : nat := 2. (*Fail 2*)

 Override Field bop := (-).

 Inherits Until MonotonicF.
 Override Family MonotonicF.
  Final Field f : nat -> nat := (+ 1).
  Field p : monotonic f := ...
 EndFamily. 
EndFamily.
\end{minted}
  \end{minipage}
  \caption{Example Code for Inheritance and Reasoning}\label{fig:plugin-example3}
\end{figure}

% explaining inheritance
Besides standalone family, we also need to implement family inheritance.
To simplify the implementation, we can consider all families as
inheritance and the standalone families are extending the empty family.
Thus, we need to deal with only inheritance during interactive theorem proving.


There are three kinds of inheritance---extend, override, and inherit. We
use first-order data to encode inheritance data inside the
implementation of the plugin. The inheritance data will include the
information of (1) the ``type'' of the parent family, (2) a list of
operation indicating how each field of the parent will be dealt with
(either inherited or overriden), (3) the operations indicating newly
extended fields, and (4) the ``type'' of the children family.
The surface syntax for the three kinds of inheritance
are demonstrated in the exemplar \cref*{fig:plugin-example3}. The
implementation of overriding, inheritance, and extension is achieved by
simply manipulating the internal representation of a family
correspondingly---we can swap the module in the list for overriding,
retain the module in the list for inheritance, and add new module into
the list for extension. The compilation from a family (internal
representation) to a module still acts the same.

Though inheritance is solely a first-order data rather
than a higher-order functor, it is still possible to
\text{mix-in} two inheritance data---by carefully ``mix'' the internal list, we can compose the inheritance. However, a good definition of mixin is still under investigation.\YZ{How about making mixin composition one of your Req's? Also does any example in the paper illustrate how to do this?}\EDJreply{mixin is not really formalized. There is no example illustrate it. The only example is the STLC example at the very end and I just kind of ``mention'' it. I think here I just want to emphasize, inheritance as first order data is still possible to support composition.}





\textbf{Reasoning Requires Non-Overridable.}
This compilation strategy
has already allowed fields to be type-dependent on former fields thus fulfilling
\ref{langdesign-req1}. However, the current implementation is not satisfactory enough. There are cases where we need to expose
the concrete definition of a given field (especially when we are proving
properties about it).

% For example, we may
% define $"add" : \mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}$ as one field
% and intend to prove its commutativity in a following field $"comm"$.
% But to prove so, we need to know more than just a type interface of
% "add" but also its \textbf{concrete fixpoint definition}. Otherwise, in the
% future, once "add" is overridden into a subtraction function then
% "comm" will have problem to be inherited.\YZ{The sentence reads as if you want to enable overriding "add", whereas what you really want is to expose the definition equality about "add".}
% A more concrete example is in \cref{fig:plugin-example1}, consider the
% case we have "Field b : a = 1 := .." instead. Then our
% compilation and Coq's type checking will both fail: in the context of
% "b" (module type "a_6") we only know "a" is of type "nat" but nothing
% more (and this is necessary so that "a" can be overridden in the
% future).
Take the field "c" in "Family I" in \cref{fig:plugin-example3} as the
example. We can see that the first attempt of proving "a = 1" fails.
This should fail, actually---because we want to retain the possibility
to override "a" in the future, but the mere existence of the field "c"
will stop that, since "c" witnesses "a" fix to "1". From the other
perspective, the proof of "c" will require a concrete definition of "a"
instead of just the exposure of its type. \textbf{We can see a conflict
between \textit{overridable} and \textit{(definition-relevant)
reasoning}}.  We enable the exposure of the concrete definition by
providing "Final" keyword upon "a'".

This example might sound trivial and contrived. Let's look at the
example field "add". Now that we only expose the type of "add", we
cannot prove its commutativity in "comm_add" (because we don't have
access to its concrete definition) but we can override "add" with
subtraction function in "Family I2". This makes sense because we
shouldn't have (inherited) commutativity property for subtraction
anyway. This is contrary to how "a'" is declared "Final", the second "c"
can prove that it's equal to 1 but "a'" is not overridable in the
"Family I2".

% To fix that, we need more information on "a" than its type---we
% need to expose the concrete definition "a = 1" to the context of "b".
%\YZ{I had a hard time working through these two paras. I guess they are
%saying that there is a need to expose definitional equalities, and
%therefore we need non-overridables. This causal flow should be made
%more explicit.}\EDJreply{Good suggestion. I try to add this casual flow into the first line of the paragraph. Please check and resolve if find satisfied.}

In our Coq plugin, we can achieve such exposure of definitional equality by
exposing the whole definition directly into the compiled module type. Doing so we also prohibit overriding because
subtraction doesn't have the same definition as $add$. We require the
users to decorate field as `Final' so that the plugin will proceed with
this special treatment.
%\YZ{This para is confusing: which kind of equality is used, propositional or judgmental? Where does 'Final' show up in the example?}\EDJreply{I rephrase it and remove the part on talking about meta-theory. Now everything is about judgemental so I don't have to emphasize judgemental. I wanted to make the example small but I guess I can add one `Final' statement into our example. Don't resolve it until I add it into Figure 2.}

\textbf{Special Fields: Overridable/Sealed Family Simulating Sigma Type.} 
Non-overridable fields are still not expressive enough to achieve the full
extent of dependent type programming. There are cases where overriding and
(definition-relevant) reasoning are both needed. For example, we may want a field to be an overridable monotonic function. We cannot split into two fields
\mintinline{Coq}{f : nat → nat} and \mintinline{Coq}{p : monotonic f},
because to provide
"p" we need to have concrete definition of "f" in the family type, which
makes "f" non-overridable at all. One option is to use sigma type
\mintinline{Coq}{{f | monotonic f}}, but that can be cumbersome when we have
a bundle of stuff with multiple refinements. 

To resolve this, we provide family sealing mechanism to simulate sigma type---we allow the
users to specify the compiled module type of a given family, and thus we
can have a \textit{non-overridable} (thus locally transparent) field
located in an \textit{overridable} family.
See, for example, the "MonotonicF" in \cref{fig:plugin-example3}.
We simply seal
\mintinline{Coq}{f : nat → nat} and \mintinline{Coq}{p : monotonic f}
together inside an overridable family that does not allow "f"
to be overridden in any of its derived families.
Because "f" is non-overridable inside the family, its definition is
transparent and can be used to prove "p".
However, because the enclosing family of "f" is overridable, to swap the
implementation of "f", we just override the whole ``sealed'' family,
like we do in "I2.MonotonicF". And the compiled module type of
"MonotonicF" will be fixed throughout the extension in different
families---it is always these two fields "f, p".\YZ{Can an overriding, sealed family define new fields not in its parent?}\EDJreply{I don't find this a problem but I didn't support it in my plugin. }

In our example, the seal family "I.MonotonicF" is actually simulating
interfaces as well.  We have
\mbox{``\mintinline{Coq}{Axiom non_impl : forall {T : Type}, T.}''},
and we have assigned it to both "f" and "p", and later instantiate in
"I2" with concrete implementation by overriding this family
"I.MonotonicF".
% Basically, {a : int -> int; property : a is monotonic}, in this case
%   we may want to override "a" using different computation, but we still wnat
%   this refinement/property



\textbf{Special Fields: ``Extensible'' Inductive Type and Defining Recursor.}
We don't actually support extensible inductive types from
\ref{langdesign-req2} in Coq (because that require non-trivial research
effort on theory side---i.e. {What is the semantics of extensible
inductive types?}---and engineering), but we simulate extensible
inductive type using overriding---when extending an inductive type $A$
with new constructors $c$, our plugin will generate a new inductive
definition $A'$ with this new $c$ on the fly and feed it to Coq.  But
still, we must be careful on the exposing data in the family type (the
compiled module type) for the following field.  

% Insert one pseudo-code example for explanation of the mechanism
% Use the natural number example
\begin{figure}[!htb]
  \begin{minipage}[t]{0.32\linewidth}
\begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}
Family B.
  FInductive b : Set 
    := tt : b | ff : b.
  Family neg_handler. 
    Field tt : self_B.b 
      := self_B.ff.
    Field ff : self_B.b 
      := self_B.tt.
  EndFamily.
  FRecursor neg 
    about self_B.b 
    motive (fun _ => self_B.b)
    using self_B.neg_handler
    by _rec.
  Field example := 
    self_B.neg self_B.tt. 
EndFamily.

Family B2 extends B.
  Extend FInductive b : Set 
    := uu : b.
  Extend Family neg_handler.
    Field uu : self_B2.b 
      := self_B2.uu.
  EndFamily. 
EndFamily.
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.65\linewidth}
\begin{minted}[fontsize=\footnotesize,escapeinside=@@]{Coq}
  (* Abstraction for Inductive Type *)
Module Type b_3 (self_B: EmptySig_4).
Parameter (b : Set). Parameter (tt ff : b). End b_3.      
Module Type b_6 := b_3 EmptyMod.
  (* Recursor to Set for b *)
Module b_rec_12 (self_B: b_6).
Definition __recursor_type_b_rec :=
  forall P : self_B.b -> Set,
  P self_B.tt -> P self_B.ff 
  -> forall __i : self_B.b, P __i. End b_rec_12. 
  (* Field B.neg_handler.ff *)
Module ff_24 (self_B: b_6) 
             (self_neg_handler: tt_23 self_B).
Definition ff : self_B.b := self_B.tt. End ff_24.
  (* Intermediate Module solely for type checking *)
Module v_33_34 (self_B: neg_handler_26).
Include b_rec_12 self_B.
Parameter (recursor_for_type_checking : __recursor_type_b_rec).
Definition term_for_type_checking :=
  recursor_for_type_checking (fun _ : self_B.b => self_B.b)
    self_B.neg_handler.tt
    self_B.neg_handler.ff.  
End v_33_34.
\end{minted}
  \end{minipage}
\caption{Example Code for Inductive Type}\label{fig:plugin-example2}
\end{figure}

Let's look at \cref{fig:plugin-example2}, the example of boolean and
negation. When we define inductive type "b", the following "Field
neg_handler.ff" can only know "b" is a type (of "Set") and there are at
least two constructors for it, just like what we declare in ``the
abstracted interface'' the compiled module type "b_3". We cannot export\YZ{export or put?}\EDJreply{Ok. I just figure out how my wording is confusing. put is absolutely correct but by put I want to mean ``export''. I think I use ``export'' in several places...}
the eliminator of "b" inside "b_3" because doing so all of the following fields (e.g. "neg_handler.ff" and the corresponding "ff_24") will not be able to be inherited to the context where "b"
is extended with a third constructor, since the existence of recursor
alone will assert that there are only two constructors in "b", not
\textbf{extensible} at all!\YZ{I can see how the existence of the recursor alone prevents extensibility, but I don't see why it has to do with ff_24.}\EDJreply{You are right. It is not only about "ff_24".I rephrased it. Please check.}

But we do have to provide a way to construct an (extensible) recursor
(as in \ref{langdesign-req3}), and perform type checking (and
exhaustiveness checking). Thus, we need to extract an elimination
principle for future usage. Here we show one exemplar extraction of the
recursor in \mintinline{Coq}{Set} as module "b_rec_12".

To construct a recursor as in \ref{langdesign-req3}, we create for each
constructor a handler and aggregate them inside a family. The whole
family "neg_handler" can be considered as a large matching case. 
Then we use
"FRecursor" to specify the motive and inductive type. Here "FRecursor"
will feed Coq
a module "v_33_34" for doing type-checking---what it does is basically
assert the existence of the recursor and apply to see if handlers can
pass the type checking by Coq. 

Once recursor is created it will look like any other function fields (and compiled in the same manner), here we show "self_B.neg" to apply to "self_B.tt" for "B.example".  While in the implementation of our plugin, the concrete recursor for this "neg" will only be created during the compilation of the surrounding family into module---it will look exactly "term_for_type_checking" but uses concrete recursor. For example, at the appropriate place, our plugin will insert a definition into the compiled module: 
\begin{minted}{Coq}
  Definition neg := b_rec (fun _ => b) neg_handler.tt neg_handler.ff.
\end{minted}
where "b_rec" and "b" are the corresponding recursor and the (vanilla) inductive type in that compiled module.


Since the recursor is constructed knowing a concrete inductive type,
thus not inheritable, for all the children, we have to reconstruct and
override with a new recursor (therefore serving as exhaustiveness
checking for children families). 
This is affordable since each recursor handler doesn't need
to be rechecked---look at "B2.neg_handler", there is only one new
handler for "uu" and the handlers from the parent
"B.neg_handler.tt,B.neg_handler.ff" have already been type-checked and
inherited (since they only rely on ``the abstracted
interface'' module "b_3"). 
Thanks to family inheritance, their corresponding compiled module from the parents---for example, 
the module "ff_24"---doesn't require another type-check and is re-used during the type-checking and compilation of "B2.neg".

Of course, our plugin will ``inherit'' the
recursor "neg" in the surface 
but what the plugin does is doing a second exhaustiveness
checking in children family.\YZ{It'd be good to show *concretely* in Figure 4
(1) code that uses the recursor and how the using code is compiled, (2)
how B2 is compiled and that compiling B2 does not require recompiling
fields inherited from B.}\EDJreply{I added both. Please check.}

% Explain why the module type need extra care

% explain how recursor is constructed
% explain we have the incremental-checking for any recursor 

% explain ftheorem wrapping this complicated recursor
We also provide a command "FTheorem" when the users want to use tactic
programming instead. This tool can avoid most boilerplate code (e.g.,
specify the handler family) when writing a recursor like above, invoke
proof interaction mode, allow tactic usage, and is also open to
extension like "FRecursor".\YZ{example?}\EDJreply{FTheorem is really just a short hand for "FRecursor" + handler family. Nothing more conceptual here. If the reader is interested in the concrete syntax, I think I need to make the two examples avaliable in the appendix.}

To summarize, the key insight here is that, to make each recursor
handler inheritable, we need to seal an abstraction around the inductive
type (e.g. module "b_3"); but to construct a recursor (and carry out the
exhaustiveness checking), we need to break this abstraction and see the
concrete definition of the inductive type (e.g. module "b_rec_12"). Our
meta-theory need to handle these two seemingly contradicting ideas
simultaneously. 


\textbf{Propositional Partial Recursor.}
Apparently, the exposed module "b_3" in \cref{fig:plugin-example2} is
not expressive enough to really fulfill \ref{langdesign-req2}. For
example, we cannot prove the constructors are injective, i.e.,
\mintinline{Coq}{self_B.tt ≠ self_B.ff}. In the original setting, to
prove injectivity of constructors of a (vanilla) inductive type, we only
require a recursor and its computational rules. However, as we pointed
out earlier, the recursor of an inductive type cannot be exposed into
the context for the sake of extensibility. Hence, we need to alter the
formulation of the recursor: we need to have a better
characterization of ``extensible inductive types'' exported in the
compiled module type as a part of the interface for the following fields
to use.


The simplest idea is to allow partiality---i.e., returning
\mintinline{Coq}{option T} instead of the original \mintinline{Coq}{T}.
We call this \textit{propositional partial recursor}.
For example, the propositional partial recursor for \mintinline{Coq}{B.b} is 
\begin{minted}[escapeinside=@@]{Coq}
b_prec : forall P : b@\YZ{b or self_B.b?}\EDJreply{it is mainly used as self_B.b, but to make option(P x) at the end doesn't require to be self_B.b so it is kind of orthognal}@ -> Set, P tt -> P ff
    -> forall x : b, option (P x).
\end{minted}
with appropriate computational axioms. The partiality doesn't break
extensibility (i.e. all future extensions of "b" can support this
"b_prec"). 

What's more, partial recursor is theoretically enough for the
"injection" and "discriminate" tactics. The rough idea to achieve this
is to use "b_prec" to reflect our special inductive type into vanilla
inductive type, and use the original "injection" and "discriminate"
tactics. For example, we want to prove \mintinline{Coq}{self_B.tt ≠
self_B.ff}, we simply 
\begin{minted}{Coq}
Definition reflect : self_B.b → option bool 
                   := b_prec (fun _ => bool) true false.
Definition tt_neq_ff : self_B.tt = self_B.ff → False.
(* Because self_B.tt = self_B.ff → reflect self_B.tt = reflect self_B.ff 
                → true = false    (by computational axiom)
                → False           (by discriminate of bool) *)
\end{minted}



In fact, the above "reflect" function implies that propositional partial
recursor is good enough to some extent, at least for non-indexed
inductive type, because we can ``embed'' vanilla inductive types into
types supporting a partial recursor. Because "reflect" is actually a left
inverse of an injection "bool → self_B.b". A bit more formally, and
restricting our focus to non-indexed inductive types,

\begin{theorem}\label{thm:prec-complete} Given a list of $n$ pairs of types $\{ x : "A"_i \vdash "B"_i(x) \}_{i}$
  \begin{itemize}
    \item Define $"C"$ as the inductive type using this list, i.e.,
    \begin{minted}{Coq}
Inductive C : Set := ... | cᵢ : forall (x : Aᵢ), (Bᵢ x -> C) -> C | ...
    \end{minted}
    \item Assume an arbitrary type \mintinline{Coq}{D : Set} with
    \begin{itemize}
      \item $n$ \textbf{functions} \mintinline{Coq}{dᵢ : forall (x : Aᵢ), (Bᵢ x -> D) -> D}  
      \item a partial recursor
      \begin{minted}[escapeinside=@@]{Coq}
prec : forall (R : Set), ..,  @\YZ{Can R be indexed?}@
  (rᵢ : (forall (x : Aᵢ), (Bᵢ x -> R) -> R)), .., D -> R
      \end{minted}
      \item and $n$ (propositional) computational axioms: for all $i$, 
      \begin{minted}{Coq}
prec {R} r₁ r₂ .. rₙ (dᵢ aᵢ bᵢ) 
    = rᵢ aᵢ (fun x => prec {R} r₁ r₂ .. rₙ (bᵢ x))
      \end{minted}
    \end{itemize}
  \end{itemize}
  Then there exists an \textbf{embedding} from "C" to "D".
  More concretely, we can have \mintinline{Coq}{inj : C -> D} and 
  \mintinline{Coq}{linv : D -> option C} defined using the eliminator of "C"\YZ{eliminator of what?}\EDJreply{"D" is not inductive type so it doesn't have eliminator} and "prec" of "D"
  (both acting like identity) such that
  \begin{minted}{Coq}
    forall c : C, linv (inj c) = some c
  \end{minted}
\end{theorem}

We emphasize that in \cref{thm:prec-complete}, each function $"d"_i$ can
actually be considered as a constructor, because they can be reflected
to real constructors of "C" using "linv". Thus, \cref{thm:prec-complete}
implies that (1) every future extension of the inductive type can
support this partial recursion (trivially); (2) every type supporting
this partial recursor with its computational axioms at least supports
these constructors because of the embedding. In other words, \textit{a
type (at least) supports these constructors if and only if this type
supports the corresponding partial recursor (with the computational
axioms)}.  Thus, we can argue that the partial recursor gives a sound and
complete characterization of all the extension of a given (non-indexed)
inductive type.\YZ{What about indexed inductive types?}

% Mention still needing total recursor, for exhaustiveness checking

\textbf{Hack: Global Reasoning.}
% explain the places using ``Closing Fact''
% 1. No need to export partial recursor
% 2. Computational rule for the total recursor
Unfortunately, there are cases the users just want global reasoning instead of an extensible proof. For example, in STLC, we should expect`` \mintinline{Coq}{~ value (tm_app x y)}'' holds in all possible extension of STLC (i.e. application is never a terminal value). We know the correct way of proving this proposition \mintinline{Coq}{value_not_app : value (tm_app x y) -> False.} is to use "FRecursor" to inductively reason "value (tm_app x y)". However, this means that everytime we extend "value" with new terminal value, we will need to extend corresponding inductive cases for "app_not_value". We can imagine the newly extended proof to be boring case analysis that the newly extended terminal value is not "tm_app". What's worse, similar scenario can happen on other statement like \mintinline{Coq}{~ value (tm_if cond x y)}. Everything here is extended correctly but we end up having boilerplate code, \textbf{semantically}.
\begin{figure}[!htb]
\begin{minted}{Coq}
Family STLC.
  FInductive tm : Set := ... 
  FInductive value : tm -> Prop := ... 
  Closing Fact value_not_app : forall x y, ~ value (tm_app x y) 
      by { intros x y H; inversion H; eauto }.
  Fail Ltac inv := 
    match goal with 
    | [h : value (tm_app _ _) |- ] => destruct (value_not_app _ _ h)
    (* Fail: value, tm_app, value_not_app unfound *)
    end. 
  MetaData tactic1.
    Ltac inv := (* ... the same definition as above ... *)
  EndMetaData.
EndFamily.
\end{minted}  
\caption{Example for Global Reasoning and MetaData}\label{fig:plugin-example-global-reasoning-meta-data}
\end{figure}


Our proposal is to allow global reasoning, which will look like a constraint inside the family. We provide "Closing Fact" as a command to carry out this global reasoning, attached with a proof script and proof term. This "Closing Fact" will look like an assertion during the construction of the surrounding family. This assertion will only be verified when the whole family is closed and compiled into a module, with the help of the attached proof script and proof terms.

Here we show the example to prove "value_not_app" in \cref{fig:plugin-example-global-reasoning-meta-data}, the script inside curly bracket after "by" is the attached proof script that will be executed when the whole family is being compiled. Since we are dealing with a concrete inductive type during compilation, we can use inversion tactic on the vanilla inductive type.  This "Closing Fact", as an assertion, will have no problem being inherited but the proof script will be executed everytime during each compilation of the children families. 

The downside is that "Closing Fact" cannot immediately check the correctness of the
attached proof term/proof script because this verification only happens when we
finished defining a family, and thus a bit harder to handle. 

Ultimately, "Closing Fact" is asserting a constraint upon all the possible extension 
of the surrounding family and claiming a proof script can solve the constraints. 
We expect it to be used in a light-weighted form for maintainability. 



% However, to verify and prove the recursor and partial recursor and their
% computational rules (as in \ref{langdesign-req4}), our plugin has to
% compile the extensible family into a non-extensible Coq Module and define
% the recursors by instantiating the content of Coq module with concrete
% inductive types. We provide "Closing Fact" as a command to carry out this global reasoning, 

% This style of ``Global Reasoning'' says that we can prove the
% corresponding theorem only when we know the ``full picture'', in particular,
% all the constructors of an inductive type. 
% We provide "Closing Fact" as
% a command to carry out this global reasoning
\YZ{Are recursors and partial recursors automatically generated and proved by the plugin, or must they be asserted and proved by the programmer?}\EDJreply{(1) Closing Fact is not only used to generate recursor and partial recursor. I think the intro of this section is just giving people wrong impression. So I rewrite the whole section now. (2)  Recursors and Partial recursors are possible to be automatically generated but my plugin didn't implement it. Current stage is that user only need to assert them. Nobody has to prove it (plugin will prove it). Here when I say the user has to provide proof script, it means for arbitrary proposition if the user want to carry out global reasoning.}
% ---we can attach to "Closing
% Fact" either (proof) terms or Coq's proof script, then only when
% compilation to module happens, is the term/proof script
% type-checked to see if a "Closing Fact" statement can be proved. Note
% that, "Closing Fact" cannot immediately check the correctness of the
% term/proof script because this verification only happens when we
% finished defining a family, and thus a bit harder to handle.

% This "Closing Fact" also can ease us from the necessity to let plugin
% generate proof for recursors and partial recursors and their
% computational rules (as in \ref{langdesign-req4}), and thus making
% plugin development easier.
\YZ{This reads like a bad excuse: the programmer does not care about if the plugin development is easy. Question is if it makes the programmer's life easier.}\EDJreply{You are right. It does sound like a bad excuse. I rewrite the whole section now. Closing Fact is initially used when the user wants global reasoning instead of extensible proof by induction, for example, the inversion lemma. \\ It just happens that they can be used by me so that I can postpone generation of these rule plugin (which is hard for me to do). This paragraph is just me being honest that my plugin is not mature enough to generate everything.}
% For example, the computation rule for a
% concrete recursor like "B.neg" and partial recursors in
% \cref{fig:plugin-example2} can be directly asserted by using "Closing
% Fact" and their proofs verified later during compilation.
\YZ{What is the alternative if not using "Closing Fact"?}\EDJreply{(1) For partial recursor and recursor, that should be generated by plugin (2) For general global reasoning, I don't know. There must be some other ways in the literature. }\YZ{Still not entirely clear to me what is gained and what is lost by using "Closing Fact".}\EDJreply{Please check.}
% This ``Global Reasoning'' will be again useful in later examples.

\textbf{Hack: ``Meta-data''.} Due to our implementation of the family,
the family data is invisible to Coq internal and thus causes some
inconvenience. For example, in \cref{fig:plugin-example-global-reasoning-meta-data} the first attempt of defining tactic inv fails. Because the earlier defining "tm", "value" and "value_not_app" are currently just data structure in the plugin and not visible for Coq internal (only visible after the family is compiled into module). 

Thus to refer to them, we have to scope the defining tactic with "MetaData" and our plugin will setup the appropriate environment. After a "MetaData" block is closed, the plugin will aggregate the content into the current defining family so that they can also be used when defining the following fields of the family. This can fulfill \ref{langdesign-req5}.\YZ{Consider adding examples of Closing Fact and MetaData, even if only to be included in an appendix.}\EDJreply{Added. Please check}

% To fulfill \ref{langdesign-req5}, we need somehow to aggregate tactic inside compiled module type, due to the implementation of our family---when defining every field of 

% For example, 

%   For example, currently it is not possible to define a
% vanilla inductive type dependent on our ``extensible'' inductive type
% due to the invisibility, unless we compile the whole family. Similarly,
% customized tactic expressions as required by \ref{langdesign-req5} cannot
% use lemmas or theorems in the fields of the current defining family as
% well.

% To remedy this, we support a "MetaData" command. This command
% bundles any original Coq primitive (in the current family
% context) into the compiled module type, and makes them visible to the
% following defining field. Doing so, we can define customized tactic as
% in \ref{langdesign-req5} that uses lemmas proved in the family.